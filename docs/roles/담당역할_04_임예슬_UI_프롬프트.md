# ë‹´ë‹¹ì—­í• : ì„ì˜ˆìŠ¬ - Streamlit UI & í”„ë¡¬í”„íŠ¸ & ì›¹ê²€ìƒ‰/íŒŒì¼ì €ì¥ ë„êµ¬

## ë‹´ë‹¹ì ì •ë³´
- **ì´ë¦„**: ì„ì˜ˆìŠ¬
- **ì—­í• **: UI ë° í”„ë¡¬í”„íŠ¸ ë‹´ë‹¹
- **ì°¸ì—¬ ê¸°ê°„**: 10/28 ~ 11/6 (ì „ì²´ ê¸°ê°„)
- **í•µì‹¬ ì—­í• **: Streamlit UI ê°œë°œ, í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, ì›¹ ê²€ìƒ‰ ë„êµ¬, íŒŒì¼ ì €ì¥ ë„êµ¬

---

## ë‹´ë‹¹ ëª¨ë“ˆ ë° ë„êµ¬

### 1. Streamlit UI (`ui/app.py`)
- ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
- LangGraph Agent ìŠ¤íŠ¸ë¦¬ë° ì—°ë™ (astream_events)
- StreamlitCallbackHandler êµ¬í˜„
- ë‚œì´ë„ ì„ íƒ UI (Easy/Hard)
- ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ (ChatMessageHistory ì—°ë™)
- íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥

### 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (`src/prompts/`)
- Langchain PromptTemplate êµ¬í˜„
- ChatPromptTemplateìœ¼ë¡œ Easy/Hard ëª¨ë“œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
- FewShotPromptTemplate (ì˜ˆì‹œ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸, ì„ íƒ)
- ë„êµ¬ë³„ í”„ë¡¬í”„íŠ¸ (SystemMessage, HumanMessage)

### 3. ë„êµ¬ 2: ì›¹ ê²€ìƒ‰ ë„êµ¬ (`src/tools/web_search.py`)
- Langchain TavilySearchResults ë„êµ¬ ì—°ë™
- @tool ë°ì½”ë ˆì´í„°ë¡œ ì»¤ìŠ¤í…€ ì›¹ ê²€ìƒ‰ ë˜í¼ êµ¬í˜„
- ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…

### 4. ë„êµ¬ 5: íŒŒì¼ ì €ì¥ ë„êµ¬ (`src/tools/file_save.py`)
- Langchain @tool ë°ì½”ë ˆì´í„°ë¡œ save_to_file êµ¬í˜„
- ëŒ€í™” ë‚´ìš© ì €ì¥
- ìš”ì•½ ë‚´ìš© ì €ì¥
- Streamlit ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì—°ë™

---

## Streamlit UI êµ¬í˜„

### 1. ê¸°ë³¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
```python
# ui/app.py

import streamlit as st
from src.agent.graph import create_agent_graph
from src.memory.chat_history import ChatMemoryManager
from langchain.callbacks.streamlit import StreamlitCallbackHandler

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë…¼ë¬¸ ë¦¬ë·° ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide"
)

# ì œëª©
st.title("ğŸ“š ë…¼ë¬¸ ë¦¬ë·° ì±—ë´‡ (AI Agent + RAG)")
st.markdown("AI/ML ë…¼ë¬¸ì„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°”: ë‚œì´ë„ ì„ íƒ
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    difficulty_mode = st.selectbox(
        "ë‹µë³€ ë‚œì´ë„ ì„ íƒ",
        ["Easy ëª¨ë“œ (ì´ˆì‹¬ììš©)", "Hard ëª¨ë“œ (ì „ë¬¸ê°€ìš©)"]
    )

    difficulty = "easy" if "Easy" in difficulty_mode else "hard"

    st.markdown("---")
    st.markdown("### ğŸ“– ì‚¬ìš© ë°©ë²•")
    st.markdown("""
    1. ë‚œì´ë„ë¥¼ ì„ íƒí•˜ì„¸ìš”
    2. ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”
    3. AI Agentê°€ ìë™ìœ¼ë¡œ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤

    **ì˜ˆì‹œ ì§ˆë¬¸:**
    - Transformer ë…¼ë¬¸ ì„¤ëª…í•´ì¤˜
    - Attentionì´ ë­ì•¼?
    - 2025ë…„ ìµœì‹  LLM ë…¼ë¬¸ì€?
    - BERT ë…¼ë¬¸ ìš”ì•½í•´ì¤˜
    """)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "memory_manager" not in st.session_state:
    st.session_state.memory_manager = ChatMemoryManager()

if "agent" not in st.session_state:
    st.session_state.agent = create_agent_graph()

# ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë…¼ë¬¸ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    # AI ë‹µë³€ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            # Agent ì‹¤í–‰
            result = st.session_state.agent.invoke({
                "question": prompt,
                "difficulty": difficulty,
                "messages": st.session_state.memory_manager.get_history()
            })

            response = result["final_answer"]

            # ë‹µë³€ í‘œì‹œ
            st.markdown(response)

    # AI ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": response})

    # ë©”ëª¨ë¦¬ì— ì¶”ê°€
    st.session_state.memory_manager.add_user_message(prompt)
    st.session_state.memory_manager.add_ai_message(response)

# ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
    st.session_state.messages = []
    st.session_state.memory_manager.clear()
    st.rerun()
```

### 2. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ê³ ê¸‰)
```python
# ui/app_streaming.py

import streamlit as st
from langchain.callbacks.streamlit import StreamlitCallbackHandler

# AI ë‹µë³€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
with st.chat_message("assistant"):
    st_callback = StreamlitCallbackHandler(st.container())

    response_placeholder = st.empty()
    full_response = ""

    # Agent ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
    async for event in st.session_state.agent.astream_events(
        {
            "question": prompt,
            "difficulty": difficulty
        },
        callbacks=[st_callback]
    ):
        # LLM ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
        if event["event"] == "on_chat_model_stream":
            chunk = event["data"]["chunk"].content
            full_response += chunk
            response_placeholder.markdown(full_response + "â–Œ")

    # ìµœì¢… ì‘ë‹µ
    response_placeholder.markdown(full_response)
```

### 3. íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥
```python
# ui/app.py (ì¶”ê°€)

import os
from datetime import datetime

# ì‚¬ì´ë“œë°”: íŒŒì¼ ì €ì¥ ê¸°ëŠ¥
with st.sidebar:
    st.markdown("---")
    st.markdown("### ğŸ’¾ íŒŒì¼ ì €ì¥")

    if st.button("ëŒ€í™” ë‚´ìš© ì €ì¥"):
        if st.session_state.messages:
            # ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            conversation_text = ""
            for msg in st.session_state.messages:
                role = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
                conversation_text += f"[{role}]\n{msg['content']}\n\n"

            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_{timestamp}.txt"

            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            st.download_button(
                label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                data=conversation_text,
                file_name=filename,
                mime="text/plain"
            )

            st.success("ëŒ€í™” ë‚´ìš©ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        else:
            st.warning("ì €ì¥í•  ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
```

---

## í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬í˜„

### 1. Easy/Hard ëª¨ë“œ í”„ë¡¬í”„íŠ¸
```python
# src/prompts/templates.py

from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    PromptTemplate
)

# Easy ëª¨ë“œ í”„ë¡¬í”„íŠ¸
EASY_MODE_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ AI/ML ë…¼ë¬¸ì„ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹µë³€ ê·œì¹™:
1. ì „ë¬¸ ìš©ì–´ê°€ ë‚˜ì˜¤ë©´ ë°˜ë“œì‹œ ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”
2. ì‹¤ìƒí™œ ë¹„ìœ ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
   - ì˜ˆ: "Attentionì€ ì‚¬ëŒì´ ì±…ì„ ì½ì„ ë•Œ ì¤‘ìš”í•œ ë¶€ë¶„ì— ì§‘ì¤‘í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤"
3. ìˆ˜ì‹ì€ ìµœì†Œí™”í•˜ê³ , ë‚˜ì˜¤ë©´ ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”
4. í•µì‹¬ ì•„ì´ë””ì–´ 3ê°€ì§€ ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”
5. ì´ˆì‹¬ìë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
"""

EASY_MODE_PROMPT = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(EASY_MODE_SYSTEM_PROMPT),
    HumanMessagePromptTemplate.from_template("{question}")
])

# Hard ëª¨ë“œ í”„ë¡¬í”„íŠ¸
HARD_MODE_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ AI/ML ì „ë¬¸ê°€ë¥¼ ìœ„í•œ ë…¼ë¬¸ ë¦¬ë·° ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ë‹µë³€ ê·œì¹™:
1. ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ ë° ìˆ˜ì‹ì„ í¬í•¨í•˜ì„¸ìš”
2. ì•Œê³ ë¦¬ì¦˜ì˜ ì‹œê°„/ê³µê°„ ë³µì¡ë„ë¥¼ ë¶„ì„í•˜ì„¸ìš”
3. ê´€ë ¨ ë…¼ë¬¸ê³¼ì˜ ë¹„êµë¥¼ ì œê³µí•˜ì„¸ìš” (ì¥ë‹¨ì )
4. êµ¬í˜„ ì‹œ ê³ ë ¤ì‚¬í•­ì„ ì„¤ëª…í•˜ì„¸ìš”
5. ìµœì‹  ì—°êµ¬ ë™í–¥ê³¼ì˜ ì—°ê²°ì„ ì œì‹œí•˜ì„¸ìš”
"""

HARD_MODE_PROMPT = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(HARD_MODE_SYSTEM_PROMPT),
    HumanMessagePromptTemplate.from_template("{question}")
])

# ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ì„ íƒ í•¨ìˆ˜
def get_difficulty_prompt(difficulty: str) -> ChatPromptTemplate:
    """ë‚œì´ë„ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
    if difficulty == "easy":
        return EASY_MODE_PROMPT
    else:
        return HARD_MODE_PROMPT
```

### 2. RAG í”„ë¡¬í”„íŠ¸
```python
# RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸

RAG_PROMPT_TEMPLATE = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template("""
    ë‹¹ì‹ ì€ ë…¼ë¬¸ ë¦¬ë·° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ë…¼ë¬¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

    [ë‹µë³€ ê·œì¹™]
    - ê²€ìƒ‰ ê²°ê³¼ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
    - ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš” (ë…¼ë¬¸ ì œëª©, ì €ì)
    - ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
    - ë‚œì´ë„: {difficulty} ëª¨ë“œ

    [ê²€ìƒ‰ ê²°ê³¼]
    {context}
    """),
    HumanMessagePromptTemplate.from_template("{question}")
])
```

### 3. Few-Shot í”„ë¡¬í”„íŠ¸ (ì„ íƒ)
```python
from langchain.prompts import FewShotPromptTemplate

# ì˜ˆì‹œ ë°ì´í„°
examples = [
    {
        "question": "Transformerê°€ ë­ì•¼?",
        "difficulty": "easy",
        "answer": "TransformerëŠ” 2017ë…„ì— ë°œí‘œëœ AI ëª¨ë¸ êµ¬ì¡°ì…ë‹ˆë‹¤. ë²ˆì—­, ìš”ì•½ ë“±ì˜ ì‘ì—…ì— ì‚¬ìš©ë©ë‹ˆë‹¤. ê°€ì¥ í° íŠ¹ì§•ì€ 'Attention' ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤."
    },
    {
        "question": "Transformerì˜ ì‹œê°„ ë³µì¡ë„ëŠ”?",
        "difficulty": "hard",
        "answer": "Transformerì˜ self-attention ë©”ì»¤ë‹ˆì¦˜ì€ O(nÂ²d) ì‹œê°„ ë³µì¡ë„ë¥¼ ê°€ì§‘ë‹ˆë‹¤. ì—¬ê¸°ì„œ nì€ ì‹œí€€ìŠ¤ ê¸¸ì´, dëŠ” ì„ë² ë”© ì°¨ì›ì…ë‹ˆë‹¤. ì´ëŠ” ê¸´ ì‹œí€€ìŠ¤ ì²˜ë¦¬ ì‹œ ë³‘ëª©ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    }
]

# Few-Shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
example_prompt = PromptTemplate(
    input_variables=["question", "difficulty", "answer"],
    template="ì§ˆë¬¸: {question}\në‚œì´ë„: {difficulty}\në‹µë³€: {answer}"
)

few_shot_prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    prefix="ë‹¤ìŒì€ ë…¼ë¬¸ ë¦¬ë·° ì±—ë´‡ì˜ ë‹µë³€ ì˜ˆì‹œì…ë‹ˆë‹¤:",
    suffix="ì§ˆë¬¸: {question}\në‚œì´ë„: {difficulty}\në‹µë³€:",
    input_variables=["question", "difficulty"]
)
```

---

## ë„êµ¬ 2: ì›¹ ê²€ìƒ‰ ë„êµ¬

### ê¸°ëŠ¥ ì„¤ëª…
ìµœì‹  ë…¼ë¬¸ ì •ë³´ë¥¼ ì›¹ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬

### Langchain êµ¬í˜„

#### 1. TavilySearchResults ì—°ë™
```python
# src/tools/web_search.py

from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.tools import tool
import os

# Langchain ê¸°ë³¸ ë„êµ¬ ì‚¬ìš©
tavily_search = TavilySearchResults(
    max_results=5,
    search_depth="advanced",
    include_answer=True,
    include_raw_content=False,
    api_key=os.getenv("TAVILY_API_KEY")
)

@tool
def search_latest_papers(query: str) -> str:
    """
    ìµœì‹  AI/ML ë…¼ë¬¸ì„ ì›¹ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì§ˆë¬¸

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ (ì œëª©, URL, ìš”ì•½)
    """
    # Tavily ê²€ìƒ‰ ì‹¤í–‰
    search_query = f"{query} AI ML paper 2024 2025 arxiv"

    results = tavily_search.invoke({"query": search_query})

    # ê²°ê³¼ í¬ë§·íŒ…
    formatted_results = format_web_search_results(results)

    return formatted_results


def format_web_search_results(results: list) -> str:
    """ì›¹ ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
    if not results:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    output = "## ğŸ” ì›¹ ê²€ìƒ‰ ê²°ê³¼\n\n"

    for i, result in enumerate(results, 1):
        title = result.get("title", "ì œëª© ì—†ìŒ")
        url = result.get("url", "")
        content = result.get("content", "")

        output += f"### {i}. {title}\n"
        output += f"- **URL**: {url}\n"
        output += f"- **ë‚´ìš©**: {content}\n\n"
        output += "---\n\n"

    return output
```

#### 2. arXiv ê²€ìƒ‰ (ì„ íƒ)
```python
from langchain_community.document_loaders import ArxivLoader

@tool
def search_arxiv(query: str, max_docs: int = 3) -> str:
    """
    arXivì—ì„œ ìµœì‹  ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ ì§ˆë¬¸
        max_docs: ìµœëŒ€ ê²€ìƒ‰ ë…¼ë¬¸ ìˆ˜

    Returns:
        arXiv ê²€ìƒ‰ ê²°ê³¼
    """
    # ArxivLoaderë¡œ ê²€ìƒ‰
    loader = ArxivLoader(query=query, max_docs=max_docs)
    docs = loader.load()

    # ê²°ê³¼ í¬ë§·íŒ…
    output = "## ğŸ“„ arXiv ê²€ìƒ‰ ê²°ê³¼\n\n"

    for i, doc in enumerate(docs, 1):
        title = doc.metadata.get("Title", "ì œëª© ì—†ìŒ")
        authors = doc.metadata.get("Authors", "ì €ì ì—†ìŒ")
        published = doc.metadata.get("Published", "ì¶œíŒì¼ ì—†ìŒ")
        summary = doc.page_content[:500]  # ìš”ì•½ 500ì

        output += f"### {i}. {title}\n"
        output += f"- **ì €ì**: {authors}\n"
        output += f"- **ì¶œíŒì¼**: {published}\n"
        output += f"- **ìš”ì•½**: {summary}...\n\n"
        output += "---\n\n"

    return output
```

### ì‚¬ìš©í•˜ëŠ” DB
**DB ì‚¬ìš© ì—†ìŒ** (ì™¸ë¶€ API í˜¸ì¶œ)

---

## ë„êµ¬ 5: íŒŒì¼ ì €ì¥ ë„êµ¬

### ê¸°ëŠ¥ ì„¤ëª…
ëŒ€í™” ë‚´ìš©, ë…¼ë¬¸ ìš”ì•½, ì°¸ê³  ìë£Œë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë„êµ¬

### Langchain êµ¬í˜„

#### 1. í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
```python
# src/tools/file_save.py

from langchain.tools import tool
import os
from datetime import datetime

@tool
def save_to_file(content: str, filename: str = None) -> str:
    """
    ë‚´ìš©ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        content: ì €ì¥í•  ë‚´ìš©
        filename: íŒŒì¼ëª… (ì„ íƒ, ì—†ìœ¼ë©´ ìë™ ìƒì„±)

    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"paper_review_{timestamp}.txt"

    # data/outputs í´ë”ì— ì €ì¥
    output_dir = "data/outputs"
    os.makedirs(output_dir, exist_ok=True)

    filepath = os.path.join(output_dir, filename)

    # íŒŒì¼ ì €ì¥
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)

    return f"âœ… íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}"
```

#### 2. Markdown í˜•ì‹ ì €ì¥
```python
@tool
def save_to_markdown(content: str, title: str = "ë…¼ë¬¸ ë¦¬ë·°", filename: str = None) -> str:
    """
    ë‚´ìš©ì„ Markdown í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        content: ì €ì¥í•  ë‚´ìš©
        title: ë¬¸ì„œ ì œëª©
        filename: íŒŒì¼ëª… (ì„ íƒ)

    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"paper_review_{timestamp}.md"

    # Markdown í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
    markdown_content = f"""# {title}

ìƒì„±ì¼: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

{content}

---

ğŸ“š Generated by ë…¼ë¬¸ ë¦¬ë·° ì±—ë´‡ (AI Agent + RAG)
"""

    # íŒŒì¼ ì €ì¥
    output_dir = "data/outputs"
    os.makedirs(output_dir, exist_ok=True)
    filepath = os.path.join(output_dir, filename)

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(markdown_content)

    return f"âœ… Markdown íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filepath}"
```

#### 3. Streamlit ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì—°ë™
```python
# ui/app.py (íŒŒì¼ ì €ì¥ UI)

import streamlit as st

# íŒŒì¼ ì €ì¥ UI
with st.sidebar:
    st.markdown("### ğŸ’¾ íŒŒì¼ ì €ì¥")

    # ì €ì¥í•  ë‚´ìš© ì„ íƒ
    save_option = st.radio(
        "ì €ì¥ ë‚´ìš© ì„ íƒ",
        ["ëŒ€í™” ë‚´ìš©", "ë§ˆì§€ë§‰ ë‹µë³€ë§Œ"]
    )

    if st.button("íŒŒì¼ ì €ì¥"):
        if save_option == "ëŒ€í™” ë‚´ìš©":
            # ì „ì²´ ëŒ€í™” ë‚´ìš©
            content = ""
            for msg in st.session_state.messages:
                role = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
                content += f"[{role}]\n{msg['content']}\n\n"
        else:
            # ë§ˆì§€ë§‰ AI ë‹µë³€ë§Œ
            if st.session_state.messages:
                last_ai_msg = [msg for msg in st.session_state.messages if msg["role"] == "assistant"][-1]
                content = last_ai_msg["content"]
            else:
                st.warning("ì €ì¥í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
                content = ""

        if content:
            # save_to_file ë„êµ¬ í˜¸ì¶œ
            result = save_to_file.invoke({"content": content})
            st.success(result)

            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            st.download_button(
                label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                data=content,
                file_name=f"paper_review_{timestamp}.txt",
                mime="text/plain"
            )
```

### ì‚¬ìš©í•˜ëŠ” DB
**DB ì‚¬ìš© ì—†ìŒ** (íŒŒì¼ ì‹œìŠ¤í…œ ì§ì ‘ ì ‘ê·¼)

---

## LangGraph í†µí•© (ì›¹ ê²€ìƒ‰/íŒŒì¼ ì €ì¥ ë…¸ë“œ)

```python
# src/agent/nodes.py

def web_search_node(state: AgentState):
    """ì›¹ ê²€ìƒ‰ ë…¸ë“œ"""
    question = state["question"]

    # ì›¹ ê²€ìƒ‰ ë„êµ¬ í˜¸ì¶œ
    search_result = search_latest_papers.invoke({"query": question})

    # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìƒíƒœì— ì €ì¥
    state["tool_result"] = search_result

    # LLMì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
    prompt = f"""
    ë‹¤ìŒ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

    ê²€ìƒ‰ ê²°ê³¼:
    {search_result}

    ì‚¬ìš©ì ì§ˆë¬¸: {question}

    ë‹µë³€:
    """

    response = llm.invoke([
        SystemMessage(content="ë‹¹ì‹ ì€ ìµœì‹  AI/ML ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
        HumanMessage(content=prompt)
    ])

    state["final_answer"] = response.content
    return state


def save_file_node(state: AgentState):
    """íŒŒì¼ ì €ì¥ ë…¸ë“œ"""
    # ì´ì „ ë‹µë³€ì„ íŒŒì¼ë¡œ ì €ì¥
    content = state.get("final_answer", "")

    if content:
        # íŒŒì¼ ì €ì¥ ë„êµ¬ í˜¸ì¶œ
        result = save_to_file.invoke({"content": content})
        state["final_answer"] = result
    else:
        state["final_answer"] = "ì €ì¥í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."

    return state
```

---

## ê°œë°œ ì¼ì •

### Phase 1: Streamlit UI ê¸°ì´ˆ ê°œë°œ (10/28~10/30)
- ê¸°ë³¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„
- ë‚œì´ë„ ì„ íƒ UI
- ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
- StreamlitCallbackHandler ì—°ë™

### Phase 2: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°œë°œ (10/31~11/02)
- Easy/Hard ëª¨ë“œ í”„ë¡¬í”„íŠ¸
- RAG í”„ë¡¬í”„íŠ¸
- FewShotPromptTemplate (ì„ íƒ)

### Phase 3: ë„êµ¬ ê°œë°œ (11/03~11/04)
- ì›¹ ê²€ìƒ‰ ë„êµ¬ (TavilySearchResults)
- íŒŒì¼ ì €ì¥ ë„êµ¬
- Streamlit ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì—°ë™

### Phase 4: ìŠ¤íŠ¸ë¦¬ë° ë° ìµœì í™” (11/04~11/05)
- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„
- UI ë””ìì¸ ê°œì„ 
- í†µí•© í…ŒìŠ¤íŠ¸

---

## Feature ë¸Œëœì¹˜

- `feature/streamlit-ui` - Streamlit UI
- `feature/prompts` - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
- `feature/tool-web-search` - ì›¹ ê²€ìƒ‰ ë„êµ¬
- `feature/tool-file-save` - íŒŒì¼ ì €ì¥ ë„êµ¬

---

## í…ŒìŠ¤íŠ¸ ì½”ë“œ

```python
# tests/test_tools.py

import pytest
from src.tools.web_search import search_latest_papers
from src.tools.file_save import save_to_file

def test_web_search():
    """ì›¹ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸"""
    result = search_latest_papers.invoke({
        "query": "transformer 2025"
    })

    assert "ê²€ìƒ‰ ê²°ê³¼" in result
    assert len(result) > 0

def test_file_save():
    """íŒŒì¼ ì €ì¥ ë„êµ¬ í…ŒìŠ¤íŠ¸"""
    content = "í…ŒìŠ¤íŠ¸ ë‚´ìš©ì…ë‹ˆë‹¤."

    result = save_to_file.invoke({
        "content": content,
        "filename": "test_file.txt"
    })

    assert "ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤" in result
    assert os.path.exists("data/outputs/test_file.txt")
```

---

## ì°¸ê³  ìë£Œ

- Streamlit ê³µì‹ ë¬¸ì„œ: https://docs.streamlit.io/
- Streamlit Chat Elements: https://docs.streamlit.io/library/api-reference/chat
- Langchain Prompts: https://python.langchain.com/docs/modules/model_io/prompts/
- Langchain Callbacks: https://python.langchain.com/docs/modules/callbacks/
- TavilySearchResults: https://python.langchain.com/docs/integrations/tools/tavily_search/
- StreamlitCallbackHandler: https://python.langchain.com/docs/integrations/callbacks/streamlit
