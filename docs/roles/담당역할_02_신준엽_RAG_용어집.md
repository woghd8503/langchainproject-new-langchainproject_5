# Îã¥ÎãπÏó≠Ìï†: Ïã†Ï§ÄÏóΩ - RAG Í≤ÄÏÉâ ÎèÑÍµ¨ & Ïö©Ïñ¥Ïßë ÎèÑÍµ¨

## Îã¥ÎãπÏûê Ï†ïÎ≥¥
- **Ïù¥Î¶Ñ**: Ïã†Ï§ÄÏóΩ
- **Ïó≠Ìï†**: RAG ÏãúÏä§ÌÖú Ï†ÑÎ¨∏ Îã¥Îãπ
- **Ï∞∏Ïó¨ Í∏∞Í∞Ñ**: 10/28 ~ 11/6 (Ï†ÑÏ≤¥ Í∏∞Í∞Ñ)
- **ÌïµÏã¨ Ïó≠Ìï†**: RAG ÌååÏù¥ÌîÑÎùºÏù∏ Íµ¨ÌòÑ, Vector DB Í≤ÄÏÉâ, Ïö©Ïñ¥Ïßë ÏãúÏä§ÌÖú

---

## Îã¥Îãπ Î™®Îìà Î∞è ÎèÑÍµ¨

### 1. RAG ÏãúÏä§ÌÖú (`src/rag/`)
- Langchain PGVector (PostgreSQL + pgvector) Ïó∞Îèô
- VectorStoreRetriever Íµ¨ÌòÑ (similarity, mmr)
- MultiQueryRetriever Íµ¨ÌòÑ (ÏøºÎ¶¨ ÌôïÏû•)
- ContextualCompressionRetriever (Î¨∏Îß• ÏïïÏ∂ï, ÏÑ†ÌÉù)
- ÏûÑÎ≤†Îî© Í¥ÄÎ¶¨ (OpenAIEmbeddings)
- Ïö©Ïñ¥Ïßë RAG ÌÜµÌï© (Î≥ÑÎèÑ pgvector Ïª¨Î†âÏÖò)

### 2. ÎèÑÍµ¨ 1: RAG Í≤ÄÏÉâ ÎèÑÍµ¨ (`src/tools/rag_search.py`)
- Langchain @tool Îç∞ÏΩîÎ†àÏù¥ÌÑ∞Î°ú search_paper_database Íµ¨ÌòÑ
- Retriever.invoke() Ìò∏Ï∂ú
- Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅ (ÎÖÑÎèÑ, Ï†ÄÏûê, Ïπ¥ÌÖåÍ≥†Î¶¨)
- Ïú†ÏÇ¨ÎèÑ Ï†êÏàò Î∞òÌôò
- PostgreSQL Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï°∞Ìöå

### 3. ÎèÑÍµ¨ 3: Ïö©Ïñ¥Ïßë ÎèÑÍµ¨ (`src/tools/glossary.py`)
- Langchain @tool Îç∞ÏΩîÎ†àÏù¥ÌÑ∞Î°ú search_glossary Íµ¨ÌòÑ
- Ïö©Ïñ¥Ïßë Ï†ÑÏö© VectorStore Í≤ÄÏÉâ
- PostgreSQL glossary ÌÖåÏù¥Î∏î ÏßÅÏ†ë Í≤ÄÏÉâ
- ÎÇúÏù¥ÎèÑÎ≥Ñ ÏÑ§Î™Ö Î∞òÌôò (Easy/Hard)
- ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâ (PostgreSQL + Vector DB)

---

## ÎèÑÍµ¨ 1: RAG Í≤ÄÏÉâ ÎèÑÍµ¨

### Í∏∞Îä• ÏÑ§Î™Ö
Î°úÏª¨ Vector DBÏôÄ PostgreSQLÏóê Ï†ÄÏû•Îêú ÎÖºÎ¨∏ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú Í¥ÄÎ†® ÎÖºÎ¨∏ÏùÑ Í≤ÄÏÉâÌïòÎäî ÎèÑÍµ¨

### Langchain Íµ¨ÌòÑ

#### 1. VectorStore Î∞è Retriever Ï¥àÍ∏∞Ìôî
```python
# src/rag/retriever.py

from langchain_postgres.vectorstores import PGVector
from langchain_openai import OpenAIEmbeddings
from langchain.retrievers import MultiQueryRetriever, ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
import os

class RAGRetriever:
    """ÎÖºÎ¨∏ Í≤ÄÏÉâÏùÑ ÏúÑÌïú RAG Retriever"""

    def __init__(self, llm):
        # OpenAI Embeddings Ï¥àÍ∏∞Ìôî
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )

        # PostgreSQL + pgvector VectorStore Ï¥àÍ∏∞Ìôî
        self.vectorstore = PGVector(
            collection_name="paper_chunks",
            embedding_function=self.embeddings,
            connection_string="postgresql://user:password@localhost:5432/papers"
        )

        # Í∏∞Î≥∏ Retriever (MMR Î∞©Ïãù)
        self.base_retriever = self.vectorstore.as_retriever(
            search_type="mmr",  # Maximal Marginal Relevance
            search_kwargs={
                "k": 5,  # ÏµúÏ¢Ö Î∞òÌôò Î¨∏ÏÑú Ïàò
                "fetch_k": 20,  # MMR ÌõÑÎ≥¥ Î¨∏ÏÑú Ïàò
                "lambda_mult": 0.5  # Í¥ÄÎ†®ÏÑ± vs Îã§ÏñëÏÑ± Í∑†Ìòï
            }
        )

        # MultiQuery Retriever (ÏøºÎ¶¨ ÌôïÏû•)
        self.multi_query_retriever = MultiQueryRetriever.from_llm(
            retriever=self.base_retriever,
            llm=llm
        )

    def retrieve(self, query: str, use_multi_query: bool = True):
        """Î¨∏ÏÑú Í≤ÄÏÉâ"""
        if use_multi_query:
            # ÏøºÎ¶¨ ÌôïÏû• ÏÇ¨Ïö©
            docs = self.multi_query_retriever.invoke(query)
        else:
            # Í∏∞Î≥∏ Í≤ÄÏÉâ
            docs = self.base_retriever.invoke(query)

        return docs

    def retrieve_with_filter(self, query: str, filter_dict: dict):
        """Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅÏùÑ Ìè¨Ìï®Ìïú Í≤ÄÏÉâ"""
        docs = self.vectorstore.similarity_search(
            query,
            k=5,
            filter=filter_dict  # Ïòà: {"year": {"$gte": 2020}}
        )
        return docs

    def retrieve_with_scores(self, query: str):
        """Ïú†ÏÇ¨ÎèÑ Ï†êÏàòÎ•º Ìè¨Ìï®Ìïú Í≤ÄÏÉâ"""
        docs_with_scores = self.vectorstore.similarity_search_with_relevance_scores(
            query,
            k=5
        )
        return docs_with_scores
```

#### 2. RAG Í≤ÄÏÉâ ÎèÑÍµ¨ Íµ¨ÌòÑ
```python
# src/tools/rag_search.py

from langchain.tools import tool
from langchain.schema import Document
import psycopg2

@tool
def search_paper_database(query: str, year_filter: int = None) -> str:
    """
    ÎÖºÎ¨∏ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú Í¥ÄÎ†® ÎÖºÎ¨∏ÏùÑ Í≤ÄÏÉâÌï©ÎãàÎã§.

    Args:
        query: Í≤ÄÏÉâÌï† ÏßàÎ¨∏ ÎòêÎäî ÌÇ§ÏõåÎìú
        year_filter: ÎÖÑÎèÑ ÌïÑÌÑ∞ (Ïòà: 2020 Ïù¥ÏÉÅ)

    Returns:
        Í¥ÄÎ†® ÎÖºÎ¨∏ ÎÇ¥Ïö© Î∞è Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
    """
    # 1. Vector DBÏóêÏÑú Ïú†ÏÇ¨ÎèÑ Í≤ÄÏÉâ
    if year_filter:
        docs = rag_retriever.retrieve_with_filter(
            query,
            filter_dict={"year": {"$gte": year_filter}}
        )
    else:
        docs = rag_retriever.retrieve(query, use_multi_query=True)

    # 2. PostgreSQLÏóêÏÑú Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï°∞Ìöå
    conn = psycopg2.connect("postgresql://user:password@localhost/papers")
    cursor = conn.cursor()

    results = []
    for doc in docs:
        paper_id = doc.metadata.get("paper_id")

        # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï°∞Ìöå
        cursor.execute(
            "SELECT title, authors, publish_date, url FROM papers WHERE paper_id = %s",
            (paper_id,)
        )
        meta = cursor.fetchone()

        if meta:
            results.append({
                "title": meta[0],
                "authors": meta[1],
                "publish_date": meta[2],
                "url": meta[3],
                "content": doc.page_content,
                "section": doc.metadata.get("section", "Î≥∏Î¨∏")
            })

    cursor.close()
    conn.close()

    # 3. Í≤∞Í≥º Ìè¨Îß∑ÌåÖ
    formatted_results = format_search_results(results)
    return formatted_results


def format_search_results(results: list) -> str:
    """Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º LLMÏóê Ï†ÑÎã¨Ìï† Ïàò ÏûàÎäî ÌòïÏãùÏúºÎ°ú Ìè¨Îß∑ÌåÖ"""
    if not results:
        return "Í¥ÄÎ†® ÎÖºÎ¨∏ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."

    output = "## Í≤ÄÏÉâÎêú ÎÖºÎ¨∏\n\n"

    for i, result in enumerate(results, 1):
        output += f"### {i}. {result['title']}\n"
        output += f"- **Ï†ÄÏûê**: {result['authors']}\n"
        output += f"- **Ï∂úÌåêÏùº**: {result['publish_date']}\n"
        output += f"- **URL**: {result['url']}\n"
        output += f"- **ÏÑπÏÖò**: {result['section']}\n\n"
        output += f"**ÎÇ¥Ïö©**:\n{result['content']}\n\n"
        output += "---\n\n"

    return output
```

#### 3. MultiQueryRetriever (ÏøºÎ¶¨ ÌôïÏû•)
```python
# MultiQueryRetriever ÎèôÏûë Î∞©Ïãù

# ÏõêÎ≥∏ ÏøºÎ¶¨: "Transformer ÎÖºÎ¨∏ ÏÑ§Î™ÖÌï¥Ï§ò"
# ‚Üí LLMÏù¥ ÏûêÎèôÏúºÎ°ú 3-5Í∞ú Î≥ÄÌòï ÏøºÎ¶¨ ÏÉùÏÑ±:
#   1. "Transformer ÏïÑÌÇ§ÌÖçÏ≤òÎûÄ?"
#   2. "Attention Is All You Need ÎÖºÎ¨∏ ÎÇ¥Ïö©"
#   3. "Transformer Î™®Îç∏Ïùò ÌïµÏã¨ Î©îÏª§ÎãàÏ¶ò"
# ‚Üí Í∞Å ÏøºÎ¶¨Î°ú Í≤ÄÏÉâ ‚Üí Í≤∞Í≥º ÌÜµÌï© ‚Üí Ï§ëÎ≥µ Ï†úÍ±∞ ‚Üí ÏµúÏ¢Ö Î∞òÌôò
```

#### 4. ContextualCompressionRetriever (ÏÑ†ÌÉù ÏÇ¨Ìï≠)
```python
# src/rag/compression.py

from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor

def create_compression_retriever(base_retriever, llm):
    """Î¨∏Îß• ÏïïÏ∂ï Retriever ÏÉùÏÑ±"""
    compressor = LLMChainExtractor.from_llm(llm)

    compression_retriever = ContextualCompressionRetriever(
        base_compressor=compressor,
        base_retriever=base_retriever
    )

    return compression_retriever

# ÏÇ¨Ïö© ÏòàÏãú
# Í∏¥ Î¨∏ÏÑúÎ•º Í≤ÄÏÉâ ÌõÑ, ÏßàÎ¨∏Í≥º Í¥ÄÎ†®Îêú Î∂ÄÎ∂ÑÎßå Ï∂îÏ∂úÌïòÏó¨ Ïª®ÌÖçÏä§Ìä∏ ÌÅ¨Í∏∞ Í∞êÏÜå
```

### ÏÇ¨Ïö©ÌïòÎäî DB

#### PostgreSQL + pgvector (Vector DB)
- **Ïª¨Î†âÏÖò**: `paper_chunks`
- **Ï†ÄÏû• Îç∞Ïù¥ÌÑ∞**: ÎÖºÎ¨∏ Î≥∏Î¨∏ÏùÑ Ï≤≠ÌÅ¨Î°ú ÎÇòÎàà ÏûÑÎ≤†Îî© Î≤°ÌÑ∞ (pgvector extension ÏÇ¨Ïö©)
- **Î©îÌÉÄÎç∞Ïù¥ÌÑ∞**:
  - `paper_id`: ÎÖºÎ¨∏ ID (PostgreSQLÍ≥º Ïó∞Í≤∞)
  - `section`: ÎÖºÎ¨∏ ÏÑπÏÖò (Abstract, Introduction Îì±)
  - `page_num`: ÌéòÏù¥ÏßÄ Î≤àÌò∏
  - `title`: ÎÖºÎ¨∏ Ï†úÎ™©
  - `authors`: Ï†ÄÏûê
  - `year`: Ï∂úÌåê ÎÖÑÎèÑ
- **Í≤ÄÏÉâ Î∞©Ïãù**:
  - Cosine Similarity (Í∏∞Î≥∏)
  - L2 Distance
  - MMR (Maximal Marginal Relevance) - Í¥ÄÎ†®ÏÑ± + Îã§ÏñëÏÑ±
  - MultiQuery (ÏøºÎ¶¨ ÌôïÏû•)

#### PostgreSQL
- **ÌÖåÏù¥Î∏î**: `papers`
  ```sql
  CREATE TABLE papers (
      paper_id SERIAL PRIMARY KEY,
      title VARCHAR(500) NOT NULL,
      authors TEXT,
      publish_date DATE,
      source VARCHAR(100),
      url TEXT UNIQUE,
      category VARCHAR(100),
      citation_count INT DEFAULT 0,
      abstract TEXT,
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
  );

  -- Ïù∏Îç±Ïä§
  CREATE INDEX idx_papers_title ON papers USING GIN (to_tsvector('english', title));
  CREATE INDEX idx_papers_category ON papers(category);
  CREATE INDEX idx_papers_date ON papers(publish_date);
  ```
- **Ïó≠Ìï†**: ÎÖºÎ¨∏ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Î∞è Ï°∞Ìöå
- **ÏøºÎ¶¨**: paper_idÎ°ú Ï†úÎ™©, Ï†ÄÏûê, ÎÖÑÎèÑ, URL Îì± Ï°∞Ìöå

---

## ÎèÑÍµ¨ 3: Ïö©Ïñ¥Ïßë ÎèÑÍµ¨

### Í∏∞Îä• ÏÑ§Î™Ö
ÎÖºÎ¨∏Ïóê ÏûêÏ£º Îì±Ïû•ÌïòÎäî Ï†ÑÎ¨∏ Ïö©Ïñ¥(Attention, Fine-tuning, BLEU Score Îì±)Î•º Í≤ÄÏÉâÌïòÏó¨ ÎÇúÏù¥ÎèÑÎ≥Ñ ÏÑ§Î™ÖÏùÑ Ï†úÍ≥µÌïòÎäî ÎèÑÍµ¨

### Langchain Íµ¨ÌòÑ

#### 1. Ïö©Ïñ¥Ïßë VectorStore Ï¥àÍ∏∞Ìôî
```python
# src/rag/glossary_retriever.py

from langchain_postgres.vectorstores import PGVector
from langchain_openai import OpenAIEmbeddings

class GlossaryRetriever:
    """Ïö©Ïñ¥Ïßë Í≤ÄÏÉâÏùÑ ÏúÑÌïú Retriever"""

    def __init__(self):
        # OpenAI Embeddings Ï¥àÍ∏∞Ìôî
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small"
        )

        # Ïö©Ïñ¥Ïßë Ï†ÑÏö© VectorStore Ï¥àÍ∏∞Ìôî (pgvector)
        self.glossary_vectorstore = PGVector(
            collection_name="glossary_embeddings",
            embedding_function=self.embeddings,
            connection_string="postgresql://user:password@localhost:5432/papers"
        )

        # Retriever ÏÑ§Ï†ï
        self.retriever = self.glossary_vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3}
        )

    def search(self, term: str):
        """Ïö©Ïñ¥ Í≤ÄÏÉâ"""
        docs = self.retriever.invoke(term)
        return docs
```

#### 2. Ïö©Ïñ¥Ïßë Í≤ÄÏÉâ ÎèÑÍµ¨ Íµ¨ÌòÑ
```python
# src/tools/glossary.py

from langchain.tools import tool
import psycopg2

@tool
def search_glossary(term: str, difficulty: str = "easy") -> str:
    """
    ÎÖºÎ¨∏ Ïö©Ïñ¥ÏßëÏóêÏÑú Ï†ÑÎ¨∏ Ïö©Ïñ¥Î•º Í≤ÄÏÉâÌïòÏó¨ ÏÑ§Î™ÖÌï©ÎãàÎã§.

    Args:
        term: Í≤ÄÏÉâÌï† Ïö©Ïñ¥
        difficulty: 'easy' (Ï¥àÏã¨Ïûê) ÎòêÎäî 'hard' (Ï†ÑÎ¨∏Í∞Ä)

    Returns:
        Ïö©Ïñ¥ Ï†ïÏùò Î∞è ÏÑ§Î™Ö
    """
    # 1. PostgreSQL glossary ÌÖåÏù¥Î∏îÏóêÏÑú ÏßÅÏ†ë Í≤ÄÏÉâ (Îπ†Î¶Ñ)
    conn = psycopg2.connect("postgresql://user:password@localhost/papers")
    cursor = conn.cursor()

    cursor.execute("""
        SELECT term, definition, easy_explanation, hard_explanation, category
        FROM glossary
        WHERE term ILIKE %s
    """, (f"%{term}%",))

    result = cursor.fetchone()

    if result:
        # PostgreSQLÏóêÏÑú Ï∞æÏùÄ Í≤ΩÏö∞
        term_name, definition, easy_exp, hard_exp, category = result

        if difficulty == "easy":
            explanation = easy_exp if easy_exp else definition
        else:
            explanation = hard_exp if hard_exp else definition

        output = f"## üìö Ïö©Ïñ¥: {term_name}\n\n"
        output += f"**Ïπ¥ÌÖåÍ≥†Î¶¨**: {category}\n\n"
        output += f"**ÏÑ§Î™Ö**:\n{explanation}\n"

        cursor.close()
        conn.close()
        return output

    cursor.close()
    conn.close()

    # 2. PostgreSQLÏóê ÏóÜÏúºÎ©¥ Vector DBÏóêÏÑú Í≤ÄÏÉâ (Ïú†Ïó∞Ìï®)
    glossary_docs = glossary_retriever.search(term)

    if glossary_docs:
        # Vector DBÏóêÏÑú Ï∞æÏùÄ Í≤ΩÏö∞
        top_doc = glossary_docs[0]
        return f"## üìö Ïö©Ïñ¥ Í¥ÄÎ†® ÎÇ¥Ïö©\n\n{top_doc.page_content}"

    # 3. Ïö©Ïñ¥ÏßëÏóêÎèÑ ÏóÜÏúºÎ©¥ ÎÖºÎ¨∏ Î≥∏Î¨∏ÏóêÏÑú Í≤ÄÏÉâ
    paper_docs = rag_retriever.retrieve(f"{term} Ï†ïÏùò", use_multi_query=False)

    if paper_docs:
        context = paper_docs[0].page_content
        return f"## üìö '{term}'Ïóê ÎåÄÌïú ÎÖºÎ¨∏ ÎÇ¥Ïö©\n\n{context}"

    return f"'{term}'Ïóê ÎåÄÌïú Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."
```

#### 3. ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâ (PostgreSQL + Vector DB)
```python
def hybrid_glossary_search(term: str, difficulty: str = "easy") -> str:
    """
    PostgreSQLÍ≥º Vector DBÎ•º ÎèôÏãúÏóê Í≤ÄÏÉâÌïòÏó¨ ÏµúÏÉÅÏùò Í≤∞Í≥º Î∞òÌôò
    """
    results = {
        "postgres": None,
        "vector_db": None
    }

    # PostgreSQL Í≤ÄÏÉâ
    conn = psycopg2.connect("postgresql://user:password@localhost/papers")
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM glossary WHERE term ILIKE %s", (f"%{term}%",))
    results["postgres"] = cursor.fetchone()
    cursor.close()
    conn.close()

    # Vector DB Í≤ÄÏÉâ
    glossary_docs = glossary_retriever.search(term)
    if glossary_docs:
        results["vector_db"] = glossary_docs[0]

    # Í≤∞Í≥º ÌÜµÌï©
    if results["postgres"]:
        # PostgreSQL Ïö∞ÏÑ† (Ï†ïÌôïÎèÑ ÎÜíÏùå)
        return format_postgres_result(results["postgres"], difficulty)
    elif results["vector_db"]:
        # Vector DB (Ïú†Ïó∞ÏÑ± ÎÜíÏùå)
        return format_vector_result(results["vector_db"])
    else:
        return f"'{term}'Ïóê ÎåÄÌïú Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."
```

#### 4. ÏßàÎ¨∏ Î∂ÑÏÑù Ïãú Ïö©Ïñ¥ ÏûêÎèô Ï∂îÏ∂ú Î∞è Ïª®ÌÖçÏä§Ìä∏ Ï∂îÍ∞Ä
```python
# src/rag/context_enhancer.py

def extract_and_add_glossary_context(user_query: str) -> str:
    """
    ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏ÏóêÏÑú Ï†ÑÎ¨∏ Ïö©Ïñ¥Î•º Ï∂îÏ∂úÌïòÏó¨ ÌîÑÎ°¨ÌîÑÌä∏Ïóê Ï∂îÍ∞Ä
    """
    conn = psycopg2.connect("postgresql://user:password@localhost/papers")
    cursor = conn.cursor()

    # ÏßàÎ¨∏ÏóêÏÑú Ïö©Ïñ¥ Ï∞æÍ∏∞ (PostgreSQL ILIKE ÏÇ¨Ïö©)
    cursor.execute("""
        SELECT term, definition, easy_explanation
        FROM glossary
        WHERE %s ILIKE '%' || term || '%'
    """, (user_query,))

    terms_found = cursor.fetchall()
    cursor.close()
    conn.close()

    if not terms_found:
        return ""

    # Ïö©Ïñ¥ Ï†ïÏùòÎ•º Ïª®ÌÖçÏä§Ìä∏Ïóê Ï∂îÍ∞Ä
    glossary_context = "\n\n## üìö Í¥ÄÎ†® Ïö©Ïñ¥ Ï†ïÏùò\n\n"
    for term, definition, easy_exp in terms_found:
        explanation = easy_exp if easy_exp else definition
        glossary_context += f"- **{term}**: {explanation}\n"

    return glossary_context
```

### ÏÇ¨Ïö©ÌïòÎäî DB

#### PostgreSQL
- **ÌÖåÏù¥Î∏î**: `glossary`
  ```sql
  CREATE TABLE glossary (
      term_id SERIAL PRIMARY KEY,
      term VARCHAR(200) NOT NULL UNIQUE,
      definition TEXT NOT NULL,
      easy_explanation TEXT,  -- Ï¥àÏã¨ÏûêÏö© ÏÑ§Î™Ö
      hard_explanation TEXT,  -- Ï†ÑÎ¨∏Í∞ÄÏö© ÏÑ§Î™Ö
      category VARCHAR(100),  -- ML, NLP, CV, RL Îì±
      difficulty_level VARCHAR(20),  -- beginner, intermediate, advanced
      related_terms TEXT[],  -- Í¥ÄÎ†® Ïö©Ïñ¥
      examples TEXT,  -- ÏÇ¨Ïö© ÏòàÏãú
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
  );

  -- Ïù∏Îç±Ïä§
  CREATE INDEX idx_glossary_term ON glossary(term);
  CREATE INDEX idx_glossary_category ON glossary(category);

  -- ÏòàÏãú Îç∞Ïù¥ÌÑ∞
  INSERT INTO glossary (term, definition, easy_explanation, hard_explanation, category, difficulty_level)
  VALUES (
      'Attention Mechanism',
      'A technique that allows models to focus on specific parts of the input when generating output.',
      'Ï±ÖÏùÑ ÏùΩÏùÑ Îïå Ï§ëÏöîÌïú Î∂ÄÎ∂ÑÏóê ÏßëÏ§ëÌïòÎäî Í≤ÉÏ≤òÎüº, AIÍ∞Ä ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï§ëÏöîÌïú Î∂ÄÎ∂ÑÏóê ÏßëÏ§ëÌïòÎäî Í∏∞Ïà†ÏûÖÎãàÎã§.',
      'A weighted sum mechanism that computes attention scores between query and key vectors, allowing the model to dynamically focus on relevant input positions during sequence processing.',
      'Deep Learning',
      'intermediate'
  );
  ```
- **Ïó≠Ìï†**: Ïö©Ïñ¥ Ï†ïÏùò Î∞è ÎÇúÏù¥ÎèÑÎ≥Ñ ÏÑ§Î™Ö Ï†ÄÏû•

#### PostgreSQL + pgvector (Vector DB)
- **Ïª¨Î†âÏÖò**: `glossary_embeddings`
- **Ï†ÄÏû• Îç∞Ïù¥ÌÑ∞**: Ïö©Ïñ¥ + Ï†ïÏùòÎ•º ÏûÑÎ≤†Îî©Ìïú Î≤°ÌÑ∞ (pgvector extension ÏÇ¨Ïö©)
- **Î©îÌÉÄÎç∞Ïù¥ÌÑ∞**:
  - `term`: Ïö©Ïñ¥Î™Ö
  - `category`: Ïπ¥ÌÖåÍ≥†Î¶¨ (ML, NLP, CV Îì±)
  - `difficulty_level`: ÎÇúÏù¥ÎèÑ
- **Í≤ÄÏÉâ Î∞©Ïãù**: Cosine Similarity, L2 Distance (Ïú†ÏÇ¨ Ïö©Ïñ¥ Í≤ÄÏÉâ)

---

## Í∞úÎ∞ú ÏùºÏ†ï

### Phase 1: RAG ÏãúÏä§ÌÖú Í∏∞Ï¥à Íµ¨ÌòÑ (10/28~10/30)
- PostgreSQL + pgvector VectorStore Ïó∞Îèô
- OpenAI Embeddings Ï¥àÍ∏∞Ìôî
- Í∏∞Î≥∏ Retriever Íµ¨ÌòÑ (similarity)
- search_paper_database ÎèÑÍµ¨ Í∏∞Î≥∏ Íµ¨ÌòÑ

### Phase 2: Í≥†Í∏â Í≤ÄÏÉâ Í∏∞Îä• Íµ¨ÌòÑ (10/31~11/02)
- MultiQueryRetriever Íµ¨ÌòÑ (ÏøºÎ¶¨ ÌôïÏû•)
- MMR Í≤ÄÏÉâ Î∞©Ïãù Ï†ÅÏö©
- Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅ
- Ïú†ÏÇ¨ÎèÑ Ï†êÏàò Î∞òÌôò

### Phase 3: Ïö©Ïñ¥Ïßë ÏãúÏä§ÌÖú Íµ¨ÌòÑ (11/01~11/02)
- Ïö©Ïñ¥Ïßë Ï†ÑÏö© VectorStore Ï¥àÍ∏∞Ìôî
- search_glossary ÎèÑÍµ¨ Íµ¨ÌòÑ
- PostgreSQL glossary ÌÖåÏù¥Î∏î Ïó∞Îèô
- ÌïòÏù¥Î∏åÎ¶¨Îìú Í≤ÄÏÉâ Íµ¨ÌòÑ

### Phase 4: ÌÜµÌï© Î∞è ÏµúÏ†ÅÌôî (11/03~11/04)
- ContextualCompressionRetriever Íµ¨ÌòÑ (ÏÑ†ÌÉù)
- Í≤ÄÏÉâ Í≤∞Í≥º Ìè¨Îß∑ÌåÖ Í∞úÏÑ†
- PostgreSQL Ïó∞Îèô ÏµúÏ†ÅÌôî
- Îã®ÏúÑ ÌÖåÏä§Ìä∏

---

## RAG ÎÖ∏Îìú Íµ¨ÌòÑ (LangGraph ÌÜµÌï©)

```python
# src/agent/nodes.py

def search_paper_node(state: AgentState):
    """RAG Í≤ÄÏÉâ ÎÖ∏Îìú"""
    question = state["question"]

    # RAG Í≤ÄÏÉâ ÎèÑÍµ¨ Ìò∏Ï∂ú
    search_result = search_paper_database.invoke({
        "query": question,
        "year_filter": None
    })

    # Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º ÏÉÅÌÉúÏóê Ï†ÄÏû•
    state["tool_result"] = search_result

    # LLMÏóê Ï†ÑÎã¨ÌïòÏó¨ ÏµúÏ¢Ö ÎãµÎ≥Ä ÏÉùÏÑ±
    difficulty = state.get("difficulty", "easy")

    prompt = f"""
    Îã§Ïùå ÎÖºÎ¨∏ Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî.

    Í≤ÄÏÉâ Í≤∞Í≥º:
    {search_result}

    ÏÇ¨Ïö©Ïûê ÏßàÎ¨∏: {question}

    ÎÇúÏù¥ÎèÑ: {difficulty}

    ÎãµÎ≥Ä:
    """

    response = llm.invoke([
        SystemMessage(content="ÎãπÏã†ÏùÄ ÎÖºÎ¨∏ Î¶¨Î∑∞ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§."),
        HumanMessage(content=prompt)
    ])

    state["final_answer"] = response.content
    return state


def glossary_node(state: AgentState):
    """Ïö©Ïñ¥Ïßë Í≤ÄÏÉâ ÎÖ∏Îìú"""
    question = state["question"]
    difficulty = state.get("difficulty", "easy")

    # ÏßàÎ¨∏ÏóêÏÑú Ïö©Ïñ¥ Ï∂îÏ∂ú (Í∞ÑÎã®Ìïú Î∞©Î≤ï)
    term = question.replace("Ïù¥ Î≠êÏïº?", "").replace("ÎûÄ?", "").strip()

    # Ïö©Ïñ¥Ïßë Í≤ÄÏÉâ ÎèÑÍµ¨ Ìò∏Ï∂ú
    glossary_result = search_glossary.invoke({
        "term": term,
        "difficulty": difficulty
    })

    state["final_answer"] = glossary_result
    return state
```

---

## Feature Î∏åÎûúÏπò

- `feature/rag-system` - RAG ÏãúÏä§ÌÖú Í∏∞Ï¥à Íµ¨ÌòÑ
- `feature/tool-rag-search` - RAG Í≤ÄÏÉâ ÎèÑÍµ¨
- `feature/tool-glossary` - Ïö©Ïñ¥Ïßë ÎèÑÍµ¨
- `feature/rag-optimization` - Í≤ÄÏÉâ ÏµúÏ†ÅÌôî (MultiQuery, MMR)

---

## ÌÖåÏä§Ìä∏ ÏΩîÎìú

```python
# tests/test_rag.py

import pytest
from src.rag.retriever import RAGRetriever
from src.tools.rag_search import search_paper_database

def test_rag_retriever():
    """RAG Retriever ÌÖåÏä§Ìä∏"""
    retriever = RAGRetriever(llm)

    # Í∏∞Î≥∏ Í≤ÄÏÉâ
    docs = retriever.retrieve("Transformer architecture")
    assert len(docs) > 0

    # ÌïÑÌÑ∞ÎßÅ Í≤ÄÏÉâ
    docs_filtered = retriever.retrieve_with_filter(
        "BERT",
        filter_dict={"year": {"$gte": 2018}}
    )
    assert len(docs_filtered) > 0

def test_search_paper_database():
    """RAG Í≤ÄÏÉâ ÎèÑÍµ¨ ÌÖåÏä§Ìä∏"""
    result = search_paper_database.invoke({
        "query": "Attention mechanism"
    })

    assert "Í≤ÄÏÉâÎêú ÎÖºÎ¨∏" in result
    assert len(result) > 0
```

---

## Ï∞∏Í≥† ÏûêÎ£å

- Langchain Retrieval: https://python.langchain.com/docs/tutorials/rag/
- Langchain Vector Stores: https://python.langchain.com/docs/integrations/vectorstores/
- Langchain PGVector: https://python.langchain.com/docs/integrations/vectorstores/pgvector/
- Langchain Retrievers: https://python.langchain.com/docs/modules/data_connection/retrievers/
- MultiQueryRetriever: https://python.langchain.com/docs/modules/data_connection/retrievers/multi_query/
- ContextualCompressionRetriever: https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression/
