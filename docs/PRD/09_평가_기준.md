# 09. í‰ê°€ ê¸°ì¤€

## ë¬¸ì„œ ì •ë³´
- **ì‘ì„±ì¼**: 2025-10-30
- **í”„ë¡œì íŠ¸ëª…**: ë…¼ë¬¸ ë¦¬ë·° ì±—ë´‡ (AI Agent + RAG)
- **íŒ€ëª…**: ì—°ê²°ì˜ ë¯¼ì¡±
- **ì‘ì„±ì**: ì—°ê²°ì˜ ë¯¼ì¡± íŒ€

---

## 1. í‰ê°€ ê°œìš”

### 1.1 í‰ê°€ ëª©ì 

- RAG ì‹œìŠ¤í…œì˜ ê²€ìƒ‰ ì •í™•ë„ ë° ë‹µë³€ í’ˆì§ˆ ì¸¡ì •
- ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ë° ë¬´ê²°ì„± ê²€ì¦
- ì‹œìŠ¤í…œ ì „ì²´ ì„±ëŠ¥ ë° ì‚¬ìš©ì ê²½í—˜ í‰ê°€

### 1.2 í‰ê°€ í”„ë¡œì„¸ìŠ¤ íë¦„

```mermaid
graph TB
    subgraph Prepare["ğŸ”¸ í‰ê°€ ì¤€ë¹„"]
        direction LR
        A[í…ŒìŠ¤íŠ¸ ë°ì´í„°<br/>ì¤€ë¹„<br/>50~200ê°œ] --> B[Ground Truth<br/>ì‘ì„±<br/>ì •ë‹µ ë¬¸ì„œ ID]
        B --> C[í‰ê°€ ë©”íŠ¸ë¦­<br/>ì„ íƒ<br/>Recall, F1 ë“±]
    end

    subgraph Execute["ğŸ”¹ í‰ê°€ ì‹¤í–‰"]
        direction TB
        D[ì‹œìŠ¤í…œ ì‹¤í–‰<br/>í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬] --> E[ê²°ê³¼ ìˆ˜ì§‘<br/>ê²€ìƒ‰ ë¬¸ì„œ, ë‹µë³€]
        E --> F[ë©”íŠ¸ë¦­ ê³„ì‚°<br/>Recall@K, F1, MRR]
        F --> G[ì„±ëŠ¥ ì§€í‘œ<br/>ì§€ì—° ì‹œê°„, ë¹„ìš©]
    end

    subgraph Analyze["ğŸ”º ë¶„ì„ & ê°œì„ "]
        direction LR
        H[ê²°ê³¼ ë¶„ì„<br/>ëª©í‘œ ëŒ€ë¹„ ë¹„êµ] --> I{ê¸°ì¤€<br/>ë§Œì¡±?}
        I -->|No| J[ì‹œìŠ¤í…œ ê°œì„ <br/>íŒŒë¼ë¯¸í„° íŠœë‹]
        I -->|Yes| K[âœ… í‰ê°€ í†µê³¼]
        J --> D
    end

    Prepare --> Execute
    Execute --> Analyze

    %% Subgraph ìŠ¤íƒ€ì¼
    style Prepare fill:#e1f5ff,stroke:#01579b,stroke-width:3px,color:#000
    style Execute fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000
    style Analyze fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼
    style A fill:#90caf9,stroke:#1976d2,color:#000
    style B fill:#64b5f6,stroke:#1976d2,color:#000
    style C fill:#42a5f5,stroke:#1565c0,color:#000
    style D fill:#ce93d8,stroke:#7b1fa2,color:#000
    style E fill:#ba68c8,stroke:#7b1fa2,color:#fff
    style F fill:#ab47bc,stroke:#4a148c,color:#fff
    style G fill:#9c27b0,stroke:#4a148c,color:#fff
    style H fill:#a5d6a7,stroke:#388e3c,color:#000
    style I fill:#ba68c8,stroke:#7b1fa2,color:#fff
    style J fill:#ffcc80,stroke:#f57c00,color:#000
    style K fill:#66bb6a,stroke:#2e7d32,color:#fff
```

### 1.2 í‰ê°€ ëŒ€ìƒ

1. **RAG ì‹œìŠ¤í…œ**: ê²€ìƒ‰ ì •í™•ë„, ë‹µë³€ ì¶©ì‹¤ì„±, ì‘ë‹µ ì†ë„
2. **RDB ì‹œìŠ¤í…œ**: ì¿¼ë¦¬ ì„±ëŠ¥, ë°ì´í„° ë¬´ê²°ì„±, ë°±ì—…/ë³µêµ¬
3. **AI Agent**: ë„êµ¬ ì„ íƒ ì •í™•ë„, ë¼ìš°íŒ… ì„±ëŠ¥
4. **UI/UX**: ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë° ê²½í—˜

---

## 2. RAG í‰ê°€ ê¸°ì¤€

### 2.1 ì •ë‹µì„±/ì¶©ì‹¤ì„± (Offline)

#### 2.1.1 Recall@K (ë¬¸ì„œ ê²€ìƒ‰)

**ì •ì˜:** ì •ë‹µ ê·¼ê±°ê°€ ìƒìœ„ K ë¬¸ì„œì— í¬í•¨ë˜ëŠ” ë¹„ìœ¨

**ì¸¡ì • ë°©ë²•:**
```python
from typing import List

def calculate_recall_at_k(
    ground_truth_docs: List[str],  # ì •ë‹µ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸
    retrieved_docs: List[str],      # ê²€ìƒ‰ëœ ë¬¸ì„œ ID ë¦¬ìŠ¤íŠ¸
    k: int
) -> float:
    """
    Recall@K ê³„ì‚°

    Args:
        ground_truth_docs: ì •ë‹µ ë¬¸ì„œ ID
        retrieved_docs: ê²€ìƒ‰ëœ ë¬¸ì„œ ID (ìƒìœ„ Kê°œ)
        k: ìƒìœ„ Kê°œ ë¬¸ì„œ

    Returns:
        Recall@K ê°’ (0.0 ~ 1.0)
    """
    top_k_docs = retrieved_docs[:k]
    relevant_retrieved = len(set(ground_truth_docs) & set(top_k_docs))
    total_relevant = len(ground_truth_docs)

    return relevant_retrieved / total_relevant if total_relevant > 0 else 0.0

# ì‚¬ìš© ì˜ˆì‹œ
ground_truth = ["doc_1", "doc_3"]
retrieved = ["doc_1", "doc_2", "doc_3", "doc_5"]

recall_3 = calculate_recall_at_k(ground_truth, retrieved, k=3)
recall_5 = calculate_recall_at_k(ground_truth, retrieved, k=5)
recall_10 = calculate_recall_at_k(ground_truth, retrieved, k=10)

print(f"Recall@3: {recall_3:.2f}")
print(f"Recall@5: {recall_5:.2f}")
print(f"Recall@10: {recall_10:.2f}")
```

**í‰ê°€ ê¸°ì¤€:**
- K âˆˆ {3, 5, 10}
- **ëª©í‘œ**: Recall@5 â‰¥ 0.6

#### 2.1.2 Precision@K

**ì •ì˜:** ìƒìœ„ K ë¬¸ì„œ ì¤‘ ì •ë‹µ ë¬¸ì„œì˜ ë¹„ìœ¨

```python
def calculate_precision_at_k(
    ground_truth_docs: List[str],
    retrieved_docs: List[str],
    k: int
) -> float:
    """Precision@K ê³„ì‚°"""
    top_k_docs = retrieved_docs[:k]
    relevant_retrieved = len(set(ground_truth_docs) & set(top_k_docs))

    return relevant_retrieved / k if k > 0 else 0.0
```

#### 2.1.3 MRR (Mean Reciprocal Rank)

**ì •ì˜:** ì²« ë²ˆì§¸ ì •ë‹µ ë¬¸ì„œì˜ ìˆœìœ„ì˜ ì—­ìˆ˜ í‰ê· 

```python
def calculate_mrr(
    queries: List[dict]  # [{"ground_truth": [...], "retrieved": [...]}, ...]
) -> float:
    """MRR ê³„ì‚°"""
    reciprocal_ranks = []

    for query in queries:
        ground_truth = set(query["ground_truth"])
        retrieved = query["retrieved"]

        for rank, doc_id in enumerate(retrieved, start=1):
            if doc_id in ground_truth:
                reciprocal_ranks.append(1.0 / rank)
                break
        else:
            reciprocal_ranks.append(0.0)

    return sum(reciprocal_ranks) / len(reciprocal_ranks) if reciprocal_ranks else 0.0
```

#### 2.1.4 EM (Exact Match) & F1 Score

**ì •ì˜:** ê¸°ì¤€ ì •ë‹µ ëŒ€ë¹„ ë‹µë³€ ì¼ì¹˜ë„

```python
def calculate_em(prediction: str, ground_truth: str) -> float:
    """Exact Match ê³„ì‚°"""
    return 1.0 if prediction.strip().lower() == ground_truth.strip().lower() else 0.0

def calculate_f1(prediction: str, ground_truth: str) -> float:
    """F1 Score ê³„ì‚° (í† í° ë‹¨ìœ„)"""
    pred_tokens = prediction.lower().split()
    truth_tokens = ground_truth.lower().split()

    common = set(pred_tokens) & set(truth_tokens)

    if len(common) == 0:
        return 0.0

    precision = len(common) / len(pred_tokens)
    recall = len(common) / len(truth_tokens)

    return 2 * (precision * recall) / (precision + recall)
```

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: EM â‰¥ 0.4 ë˜ëŠ” F1 â‰¥ 0.6

#### 2.1.5 Faithfulness (í™˜ê°ë¥ )

**ì •ì˜:** ë‹µë³€ì´ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ê·¼ê±°í•˜ëŠ” ë¹„ìœ¨ (= 1 - í™˜ê°ë¥ )

```python
from langchain.evaluation import load_evaluator

def calculate_faithfulness(
    query: str,
    answer: str,
    context: str,
    llm
) -> float:
    """
    Faithfulness ê³„ì‚° (RAGAS ë°©ì‹)

    Returns:
        0.0 ~ 1.0 (1.0ì´ ê°€ì¥ ì¶©ì‹¤í•¨)
    """
    evaluator = load_evaluator("qa", llm=llm)

    result = evaluator.evaluate_strings(
        prediction=answer,
        reference=context,
        input=query
    )

    return result.get("score", 0.0)
```

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: Faithfulness â‰¥ 0.9 (í™˜ê°ë¥  â‰¤ 10%)

#### 2.1.6 Context Utilization (%)

**ì •ì˜:** ë‹µë³€ì´ ì‹¤ì œë¡œ ì–´ëŠ ì»¨í…ìŠ¤íŠ¸ ì¡°ê°ì„ ì°¸ì¡°í–ˆëŠ”ì§€ ë§¤ì¹­ ë¹„ìœ¨

```python
def calculate_context_utilization(
    answer: str,
    context_chunks: List[str]
) -> float:
    """
    ë‹µë³€ì´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ í™œìš©í–ˆëŠ”ì§€ ê³„ì‚°

    Returns:
        0.0 ~ 1.0
    """
    used_chunks = 0

    for chunk in context_chunks:
        # ì²­í¬ì˜ ì£¼ìš” í‚¤ì›Œë“œê°€ ë‹µë³€ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        chunk_keywords = set(chunk.lower().split())
        answer_keywords = set(answer.lower().split())

        overlap = len(chunk_keywords & answer_keywords)
        if overlap / len(chunk_keywords) > 0.3:  # 30% ì´ìƒ ê²¹ì¹˜ë©´ ì‚¬ìš©
            used_chunks += 1

    return used_chunks / len(context_chunks) if context_chunks else 0.0
```

---

### 2.2 íš¨ìœ¨ì„± (Online/Latency)

#### 2.2.1 End-to-End ì§€ì—° (ms)

**ì •ì˜:** ê²€ìƒ‰ + ìƒì„± ì´ ì†Œìš”ì‹œê°„

```python
import time

def measure_end_to_end_latency(query: str, agent) -> dict:
    """E2E ì§€ì—° ì¸¡ì •"""
    start_time = time.time()

    response = agent.invoke({"question": query})

    end_time = time.time()
    latency_ms = (end_time - start_time) * 1000

    return {
        "latency_ms": latency_ms,
        "response": response
    }

# ì—¬ëŸ¬ ì¿¼ë¦¬ì— ëŒ€í•´ ì¸¡ì •
latencies = []
for query in test_queries:
    result = measure_end_to_end_latency(query, agent)
    latencies.append(result["latency_ms"])

# p50, p95 ê³„ì‚°
import numpy as np
p50 = np.percentile(latencies, 50)
p95 = np.percentile(latencies, 95)

print(f"p50 ì§€ì—°: {p50:.2f}ms")
print(f"p95 ì§€ì—°: {p95:.2f}ms")
```

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: p95 ì§€ì—° â‰¤ 6000ms (6ì´ˆ)

#### 2.2.2 í† í° ë¹„ìš©/í˜¸ì¶œ ë¹„ìš© (ì›)

**ì •ì˜:** ì§ˆë¬¸ë‹¹ í‰ê·  í”„ë¡¬í”„íŠ¸/ì¶œë ¥ í† í° ìˆ˜, API ë¹„ìš© ì¶”ì •

```python
from langchain.callbacks import get_openai_callback

def calculate_cost(queries: List[str], agent) -> dict:
    """í† í° ë¹„ìš© ê³„ì‚°"""
    total_tokens = 0
    total_cost = 0.0

    with get_openai_callback() as cb:
        for query in queries:
            agent.invoke({"question": query})

        total_tokens = cb.total_tokens
        total_cost = cb.total_cost

    avg_tokens = total_tokens / len(queries)
    avg_cost = total_cost / len(queries)

    return {
        "total_tokens": total_tokens,
        "avg_tokens_per_query": avg_tokens,
        "total_cost_usd": total_cost,
        "avg_cost_per_query_usd": avg_cost,
        "avg_cost_per_query_krw": avg_cost * 1300  # USD to KRW
    }
```

---

### 2.3 ê°•ê±´ì„±

#### 2.3.1 No-Answer Handling

**ì •ì˜:** ê·¼ê±° ë¶€ì¬ ì‹œ "ê·¼ê±° ì—†ìŒ" ì‘ë‹µì„ ì •í™•íˆ ë°˜í™˜í•˜ëŠ” ë¹„ìœ¨

```python
def evaluate_no_answer_handling(
    queries_without_answer: List[str],
    agent
) -> float:
    """No-Answer ì²˜ë¦¬ ì •í™•ë„"""
    correct_no_answer = 0

    for query in queries_without_answer:
        response = agent.invoke({"question": query})

        # "ê·¼ê±° ì—†ìŒ", "ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ë“±ì˜ í‚¤ì›Œë“œ í™•ì¸
        no_answer_keywords = ["ê·¼ê±° ì—†ìŒ", "ë‹µë³€í•  ìˆ˜ ì—†", "ì •ë³´ê°€ ì—†", "ì°¾ì„ ìˆ˜ ì—†"]

        if any(keyword in response for keyword in no_answer_keywords):
            correct_no_answer += 1

    return correct_no_answer / len(queries_without_answer)
```

#### 2.3.2 ê¸¸ì´/ì¡ìŒ ë¯¼ê°ë„

**ì •ì˜:** ë§¤ìš° ê¸´ ìš”ì•½/ë¬¸ì„œ ì„ì„/ì¤‘ë³µ ì»¨í…ì¸ ì—ì„œ ì„±ëŠ¥ ì €í•˜ ì •ë„

**ì¸¡ì • ë°©ë²•:**
- ì •ìƒ ë¬¸ì„œ vs ê¸´ ë¬¸ì„œ (10ë°° ê¸¸ì´)ì—ì„œ Recall@5 ë¹„êµ
- ë…¸ì´ì¦ˆ ë¬¸ì„œ ì¶”ê°€ ì‹œ ì„±ëŠ¥ ì €í•˜ìœ¨ ì¸¡ì •

---

### 2.4 ê¶Œì¥ íˆ´/í”„ë¡œí† ì½œ

#### 2.4.1 ë°ì´í„°ì…‹

**ì¤€ë¹„:**
- ì†Œê·œëª¨ GT (Ground Truth) ì¿¼ë¦¬-ì •ë‹µ-ê·¼ê±° ì„¸íŠ¸ ì¤€ë¹„
- ê·œëª¨: 50~200ê°œ
- í˜•ì‹: CSV ë˜ëŠ” JSON

**ì˜ˆì‹œ (CSV):**
```csv
query,ground_truth_answer,ground_truth_docs,difficulty
Transformer ë…¼ë¬¸ì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ”?,"Self-Attention ë©”ì»¤ë‹ˆì¦˜, Encoder-Decoder êµ¬ì¡°, Positional Encoding","doc_1,doc_3",easy
BERTì˜ pre-training ë°©ë²•ì€?,"Masked Language Model (MLM), Next Sentence Prediction (NSP)","doc_5,doc_7",hard
```

#### 2.4.2 ë„êµ¬

**ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬:**
- `ragas`: RAG í‰ê°€ ì „ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
- `langchain.evaluation`: Langchain ë‚´ì¥ í‰ê°€ ë„êµ¬
- ìˆ˜ë™ íŒì • í…œí”Œë¦¿ (Streamlit ë‚´ í‘œì¶œ)

**ì˜ˆì‹œ:**
```python
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy, context_recall

# RAGAS í‰ê°€
results = evaluate(
    dataset,
    metrics=[
        faithfulness,
        answer_relevancy,
        context_recall
    ]
)

print(results)
```

#### 2.4.3 ì ˆì°¨

1. **ì¸ë±ìŠ¤ ê³ ì •**: VectorDB ì¸ë±ìŠ¤ ë¹Œë“œ í›„ ë³€ê²½ ê¸ˆì§€
2. **ì¿¼ë¦¬ ë°°ì¹˜ ì‹¤í–‰**: í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì „ì²´ ì‹¤í–‰
3. **ë©”íŠ¸ë¦­ ì‚°ì¶œ**: Recall@K, Faithfulness ë“± ê³„ì‚°
4. **ë¦¬ê·¸ë ˆì…˜ ì¶”ì **: ë³€ê²½ ì „í›„ ì„±ëŠ¥ ë¹„êµ

---

### 2.5 ê¶Œì¥ ìˆ˜ìš© ê¸°ì¤€ (ì´ˆê¸° PoC)

| ë©”íŠ¸ë¦­ | ëª©í‘œ ê°’ |
|--------|---------|
| **Recall@5** | â‰¥ 0.6 |
| **EM** | â‰¥ 0.4 |
| **F1** | â‰¥ 0.6 |
| **Faithfulness** | â‰¥ 0.9 |
| **p95 ì§€ì—°** | â‰¤ 6000ms (6ì´ˆ) |

---

## 3. RDB í‰ê°€ ê¸°ì¤€

### 3.1 ì„±ëŠ¥/íš¨ìœ¨

#### 3.1.1 Query Latency (ms)

**ì •ì˜:** ì£¼ìš” ì¿¼ë¦¬ì˜ p50/p95 ì§€ì—° ì‹œê°„

**ì¸¡ì • ëŒ€ìƒ:**
- `papers` í…Œì´ë¸” ìµœì‹  Nê±´ ì¡°íšŒ
- `term` ìƒìœ„ Nê°œ ì¡°íšŒ
- ë³µì¡í•œ JOIN ì¿¼ë¦¬

```python
import psycopg2
import time

def measure_query_latency(query: str, conn, iterations: int = 100) -> dict:
    """ì¿¼ë¦¬ ì§€ì—° ì¸¡ì •"""
    latencies = []

    cursor = conn.cursor()

    for _ in range(iterations):
        start_time = time.time()
        cursor.execute(query)
        cursor.fetchall()
        end_time = time.time()

        latency_ms = (end_time - start_time) * 1000
        latencies.append(latency_ms)

    cursor.close()

    import numpy as np
    return {
        "p50_ms": np.percentile(latencies, 50),
        "p95_ms": np.percentile(latencies, 95),
        "avg_ms": np.mean(latencies)
    }

# ì‚¬ìš© ì˜ˆì‹œ
conn = psycopg2.connect("postgresql://user:password@localhost/papers")

# ìµœì‹  10ê±´ ì¡°íšŒ
query = "SELECT * FROM papers ORDER BY created_at DESC LIMIT 10"
result = measure_query_latency(query, conn)
print(f"p50: {result['p50_ms']:.2f}ms, p95: {result['p95_ms']:.2f}ms")
```

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: p95 ì¡°íšŒ ì§€ì—° â‰¤ 50ms

#### 3.1.2 Insert/Upsert Throughput

**ì •ì˜:** ì´ˆë‹¹ ì²˜ë¦¬ ê±´ìˆ˜, ë°°ì¹˜ ì‚½ì… ì‹œ í‰ê·  ì†Œìš”

```python
def measure_insert_throughput(data: List[dict], conn) -> dict:
    """ì‚½ì… ì²˜ë¦¬ëŸ‰ ì¸¡ì •"""
    cursor = conn.cursor()

    start_time = time.time()

    for row in data:
        cursor.execute("""
            INSERT INTO papers (title, authors, publish_date, url, abstract)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (url) DO NOTHING
        """, (row['title'], row['authors'], row['publish_date'], row['url'], row['abstract']))

    conn.commit()
    end_time = time.time()

    duration = end_time - start_time
    throughput = len(data) / duration

    cursor.close()

    return {
        "total_rows": len(data),
        "duration_sec": duration,
        "throughput_per_sec": throughput,
        "avg_latency_ms": (duration / len(data)) * 1000
    }
```

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: p95 ì‚½ì… ì§€ì—° â‰¤ 30ms

#### 3.1.3 íŒŒì¼ í¬ê¸°/ì„±ì¥ë¥ 

**ì •ì˜:** `papers.db` í¬ê¸°, ì£¼ë‹¹ ì¦ê°€ëŸ‰, VACUUM í›„ ì ˆê°ë¥ 

```bash
# PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° í™•ì¸
psql -U user -d papers -c "
SELECT
    pg_size_pretty(pg_database_size('papers')) AS database_size;
"

# í…Œì´ë¸”ë³„ í¬ê¸°
psql -U user -d papers -c "
SELECT
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
"

# VACUUM ì‹¤í–‰
psql -U user -d papers -c "VACUUM FULL ANALYZE;"
```

---

### 3.2 ë¬´ê²°ì„±/í’ˆì§ˆ

#### 3.2.1 ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„±

**ì •ì˜:** NULL/íƒ€ì… ìœ„ë°˜ 0ê±´, ì œì•½ì¡°ê±´ ìœ„ë°˜ 0ê±´

```sql
-- NULL ì²´í¬
SELECT COUNT(*) AS null_count
FROM papers
WHERE title IS NULL OR authors IS NULL;

-- íƒ€ì… ìœ„ë°˜ ì²´í¬ (ì˜ˆ: ë‚ ì§œ í˜•ì‹)
SELECT COUNT(*) AS invalid_dates
FROM papers
WHERE publish_date > CURRENT_DATE;

-- ì œì•½ì¡°ê±´ ìœ„ë°˜ ì²´í¬
SELECT constraint_name, table_name
FROM information_schema.table_constraints
WHERE constraint_type = 'CHECK';
```

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: NULL/íƒ€ì… ìœ„ë°˜ 0ê±´

#### 3.2.2 ì¤‘ë³µë¥ 

**ì •ì˜:** ë™ì¼ URL/ID ì¤‘ë³µ ì‚½ì… ë¹„ìœ¨ (UPSERT ì •ì±…ìœ¼ë¡œ 0ì— ê·¼ì ‘)

```sql
-- URL ì¤‘ë³µ ì²´í¬
SELECT url, COUNT(*) AS duplicate_count
FROM papers
GROUP BY url
HAVING COUNT(*) > 1;

-- ì¤‘ë³µë¥  ê³„ì‚°
SELECT
    (SELECT COUNT(*) FROM (
        SELECT url FROM papers GROUP BY url HAVING COUNT(*) > 1
    ) AS duplicates) * 100.0 / COUNT(*) AS duplicate_rate_percent
FROM papers;
```

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: ì¤‘ë³µë¥  â‰¤ 1%

#### 3.2.3 ë°±ì—…/ë³µêµ¬ í…ŒìŠ¤íŠ¸

**ì •ì˜:** ì£¼ 1íšŒ ë°±ì—… í›„ ë³µì› ì„±ê³µë¥  100%

```bash
# ë°±ì—…
pg_dump -U user -d papers -F c -f backup_$(date +%Y%m%d).dump

# ë³µì› (í…ŒìŠ¤íŠ¸ DBë¡œ)
createdb papers_test
pg_restore -U user -d papers_test backup_20251030.dump

# ë³µì› ê²€ì¦
psql -U user -d papers_test -c "SELECT COUNT(*) FROM papers;"
```

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: ë³µêµ¬ ì„±ê³µë¥  100%

---

### 3.3 ìœ ì§€ë³´ìˆ˜ì„±

#### 3.3.1 ì¸ë±ìŠ¤ í™œìš©ë„

**ì •ì˜:** `EXPLAIN QUERY PLAN`ìœ¼ë¡œ í’€ìŠ¤ìº” íšŒí”¼ í™•ì¸

```sql
-- ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš í™•ì¸
EXPLAIN ANALYZE
SELECT * FROM papers WHERE title LIKE '%Transformer%';

-- ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€ í™•ì¸
-- "Index Scan" ë˜ëŠ” "Bitmap Index Scan"ì´ ë‚˜ì˜¤ë©´ OK
-- "Seq Scan"ì´ ë‚˜ì˜¤ë©´ í’€ìŠ¤ìº” (ì¸ë±ìŠ¤ ë¯¸ì‚¬ìš©)
```

#### 3.3.2 ë§ˆì´ê·¸ë ˆì´ì…˜ ìš©ì´ì„±

**ì •ì˜:** ì»¬ëŸ¼ ì¶”ê°€ ì‹œ ê¸°ì¡´ ì¿¼ë¦¬ í˜¸í™˜ì„± ìœ ì§€ìœ¨

```sql
-- ì»¬ëŸ¼ ì¶”ê°€ (ì˜ˆ: tags)
ALTER TABLE papers ADD COLUMN tags TEXT[];

-- ê¸°ì¡´ ì¿¼ë¦¬ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸
-- ê¸°ì¡´ ì¿¼ë¦¬ê°€ ì—¬ì „íˆ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
SELECT title, authors FROM papers LIMIT 10;
```

---

### 3.4 ê¶Œì¥ íˆ´/í”„ë¡œí† ì½œ

- **CLI**: `psql`, `pg_dump`, `pg_restore`
- **EXPLAIN QUERY PLAN**: ì¿¼ë¦¬ ìµœì í™”
- **ANALYZE**: í†µê³„ ì •ë³´ ê°±ì‹ 
- **Streamlit ì§„ë‹¨ íƒ­** (ì„ íƒ): ìµœê·¼ ë ˆì½”ë“œ ìˆ˜, íŒŒì¼ í¬ê¸°, ì¸ë±ìŠ¤ ìœ ë¬´ í‘œì‹œ

---

### 3.5 ê¶Œì¥ ìˆ˜ìš© ê¸°ì¤€ (ì´ˆê¸° PoC)

| ë©”íŠ¸ë¦­ | ëª©í‘œ ê°’ |
|--------|---------|
| **p95 ì¡°íšŒ ì§€ì—°** | â‰¤ 50ms |
| **p95 ì‚½ì… ì§€ì—°** | â‰¤ 30ms |
| **ì¤‘ë³µë¥ ** | â‰¤ 1% |
| **ë³µêµ¬ ì„±ê³µë¥ ** | 100% |

---

## 4. AI Agent í‰ê°€ ê¸°ì¤€

### 4.1 ë„êµ¬ ì„ íƒ ì •í™•ë„

**ì •ì˜:** ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ì˜¬ë°”ë¥¸ ë„êµ¬ë¥¼ ì„ íƒí•œ ë¹„ìœ¨

```python
def evaluate_tool_selection(test_cases: List[dict], agent) -> float:
    """
    ë„êµ¬ ì„ íƒ ì •í™•ë„ í‰ê°€

    test_cases: [
        {"query": "...", "expected_tool": "search_paper"},
        ...
    ]
    """
    correct = 0

    for case in test_cases:
        # Agent ì‹¤í–‰ (ë„êµ¬ ì„ íƒë§Œ í™•ì¸)
        result = agent.invoke({"question": case["query"]})

        # ì‹¤ì œ ì‚¬ìš©ëœ ë„êµ¬ í™•ì¸
        used_tool = result.get("tool_used")

        if used_tool == case["expected_tool"]:
            correct += 1

    return correct / len(test_cases)
```

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: ë„êµ¬ ì„ íƒ ì •í™•ë„ â‰¥ 0.85

### 4.2 ë¼ìš°íŒ… ì§€ì—°

**ì •ì˜:** ë¼ìš°íŒ… ê²°ì •ì— ì†Œìš”ë˜ëŠ” ì‹œê°„

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: í‰ê·  ë¼ìš°íŒ… ì§€ì—° â‰¤ 500ms

---

## 5. UI/UX í‰ê°€ ê¸°ì¤€

### 5.1 ì‚¬ìš©ì ë§Œì¡±ë„

**ì •ì˜:** ì‚¬ìš©ì ì„¤ë¬¸ ì¡°ì‚¬ (1~5ì )

**í‰ê°€ í•­ëª©:**
1. ì¸í„°í˜ì´ìŠ¤ ì§ê´€ì„±
2. ì‘ë‹µ ì†ë„ ë§Œì¡±ë„
3. ë‹µë³€ í’ˆì§ˆ ë§Œì¡±ë„
4. ì „ì²´ ë§Œì¡±ë„

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: í‰ê·  ë§Œì¡±ë„ â‰¥ 4.0 / 5.0

### 5.2 UI ì‘ë‹µì„±

**ì •ì˜:** UI ë Œë”ë§ ë° ìƒí˜¸ì‘ìš© ì§€ì—°

**í‰ê°€ ê¸°ì¤€:**
- **ëª©í‘œ**: ë²„íŠ¼ í´ë¦­ ~ ì‘ë‹µ ì‹œì‘ â‰¤ 1ì´ˆ

---

## 6. í†µí•© í‰ê°€ ì‹œë‚˜ë¦¬ì˜¤

### 6.1 ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ (10ê°œ)

| ë²ˆí˜¸ | ì‹œë‚˜ë¦¬ì˜¤ | ê¸°ëŒ€ ë„êµ¬ | ê¸°ëŒ€ ê²°ê³¼ |
|------|----------|-----------|----------|
| 1 | "Transformer ë…¼ë¬¸ ì„¤ëª…í•´ì¤˜" (Easy) | RAG ê²€ìƒ‰ | ì‰¬ìš´ ì„¤ëª… ì œê³µ |
| 2 | "BERTì™€ GPTì˜ ì°¨ì´ëŠ”?" (Hard) | RAG ê²€ìƒ‰ | ê¸°ìˆ ì  ë¹„êµ ì œê³µ |
| 3 | "Attention Mechanismì´ ë­ì•¼?" | ìš©ì–´ì§‘ | ìš©ì–´ ì •ì˜ ì œê³µ |
| 4 | "2025ë…„ ìµœì‹  LLM ë…¼ë¬¸ì€?" | ì›¹ ê²€ìƒ‰ | ìµœì‹  ë…¼ë¬¸ ê²€ìƒ‰ |
| 5 | "Attention Is All You Need ë…¼ë¬¸ ìš”ì•½í•´ì¤˜" | ë…¼ë¬¸ ìš”ì•½ | ë‚œì´ë„ë³„ ìš”ì•½ ì œê³µ |
| 6 | "ì´ ìš”ì•½ ë‚´ìš© íŒŒì¼ë¡œ ì €ì¥í•´ì¤˜" | íŒŒì¼ ì €ì¥ | íŒŒì¼ ìƒì„± í™•ì¸ |
| 7 | "Self-Attentionì´ ë­ì•¼?" | ìš©ì–´ì§‘ | ìš©ì–´ ì •ì˜ ì œê³µ |
| 8 | "Transformerì˜ ì¥ì ì€?" | RAG ê²€ìƒ‰ | ê´€ë ¨ ì •ë³´ ì œê³µ |
| 9 | "BERT ë…¼ë¬¸ì˜ í•µì‹¬ ê¸°ì—¬ëŠ”?" | RAG ê²€ìƒ‰ | í•µì‹¬ ë‚´ìš© ì œê³µ |
| 10 | "ìµœì‹  ë©€í‹°ëª¨ë‹¬ AI ë…¼ë¬¸ ì°¾ì•„ì¤˜" | ì›¹ ê²€ìƒ‰ | ìµœì‹  ë…¼ë¬¸ ê²€ìƒ‰ |

### 6.2 í†µí•© í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] 10ê°œ ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë‘ ì •ìƒ ë™ì‘
- [ ] ë„êµ¬ ì„ íƒ ì •í™•ë„ â‰¥ 85%
- [ ] í‰ê·  ì‘ë‹µ ì‹œê°„ â‰¤ 6ì´ˆ
- [ ] Faithfulness â‰¥ 0.9
- [ ] UI ì •ìƒ ë Œë”ë§
- [ ] ì˜¤ë¥˜ ì—†ìŒ

---

## 7. í‰ê°€ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

### 7.1 RAG í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/evaluate_rag.py

from src.utils.logger import Logger
import os
from datetime import datetime

def run_rag_evaluation():
    # ë¡œê·¸ í´ë” ìƒì„±
    today = datetime.now().strftime("%Y%m%d")
    time_now = datetime.now().strftime("%H%M%S")
    experiment_name = "eval_rag_system"
    log_dir = f"experiments/{today}/{today}_{time_now}_{experiment_name}"
    os.makedirs(log_dir, exist_ok=True)

    logger = Logger(f"{log_dir}/rag_evaluation.log")

    logger.write("=" * 60)
    logger.write("RAG ì‹œìŠ¤í…œ í‰ê°€ ì‹œì‘")
    logger.write("=" * 60)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    test_data = load_test_data("data/test/rag_testset.csv")
    logger.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data)}ê±´")

    # Recall@K í‰ê°€
    recall_3 = evaluate_recall_at_k(test_data, k=3)
    recall_5 = evaluate_recall_at_k(test_data, k=5)
    recall_10 = evaluate_recall_at_k(test_data, k=10)

    logger.write(f"Recall@3: {recall_3:.2f}")
    logger.write(f"Recall@5: {recall_5:.2f}")
    logger.write(f"Recall@10: {recall_10:.2f}")

    # Faithfulness í‰ê°€
    faithfulness = evaluate_faithfulness(test_data)
    logger.write(f"Faithfulness: {faithfulness:.2f}")

    # ì§€ì—° ì‹œê°„ í‰ê°€
    latencies = evaluate_latency(test_data)
    logger.write(f"p50 ì§€ì—°: {latencies['p50']:.2f}ms")
    logger.write(f"p95 ì§€ì—°: {latencies['p95']:.2f}ms")

    # ê²°ê³¼ ì €ì¥
    results = {
        "recall_3": recall_3,
        "recall_5": recall_5,
        "recall_10": recall_10,
        "faithfulness": faithfulness,
        "p50_latency_ms": latencies["p50"],
        "p95_latency_ms": latencies["p95"]
    }

    import json
    with open(f"{log_dir}/results.json", "w") as f:
        json.dump(results, f, indent=2)

    logger.write("=" * 60)
    logger.write("RAG í‰ê°€ ì™„ë£Œ")
    logger.write("=" * 60)
    logger.close()

if __name__ == "__main__":
    run_rag_evaluation()
```

---

## 8. ì°¸ê³  ìë£Œ

- RAGAS: https://github.com/explodinggradients/ragas
- Langchain Evaluation: https://python.langchain.com/docs/guides/evaluation/
- PostgreSQL Performance: https://www.postgresql.org/docs/current/performance-tips.html
- Information Retrieval Metrics: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)
