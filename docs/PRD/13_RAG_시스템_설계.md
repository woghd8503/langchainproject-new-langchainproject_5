# 13. RAG ì‹œìŠ¤í…œ ì„¤ê³„

## ë¬¸ì„œ ì •ë³´
- **ì‘ì„±ì¼**: 2025-10-30
- **í”„ë¡œì íŠ¸ëª…**: ë…¼ë¬¸ ë¦¬ë·° ì±—ë´‡ (AI Agent + RAG)
- **íŒ€ëª…**: ì—°ê²°ì˜ ë¯¼ì¡±

---

## 1. RAG íŒŒì´í”„ë¼ì¸

### 1.1 ì „ì²´ íë¦„

```mermaid
graph TB
    subgraph Prepare["ğŸ”¸ ë°ì´í„° ì¤€ë¹„"]
        direction LR
        A[ë…¼ë¬¸ ìˆ˜ì§‘<br/>arXiv] --> B[í…ìŠ¤íŠ¸ ì¶”ì¶œ<br/>PDF â†’ Text]
        B --> C[ì²­í¬ ë¶„í• <br/>1000ì ë‹¨ìœ„]
        C --> D[ì„ë² ë”©<br/>OpenAI]
        D --> E[ğŸ’¾ VectorDB<br/>pgvector]
    end

    subgraph Search["ğŸ”¹ ê²€ìƒ‰"]
        direction LR
        F[ì‚¬ìš©ì ì§ˆë¬¸] --> G[ì§ˆë¬¸ ì„ë² ë”©]
        G --> H[ìœ ì‚¬ë„ ê²€ìƒ‰<br/>Top-K]
        H --> I[ê´€ë ¨ ë¬¸ì„œ]
    end

    subgraph Generate["ğŸ”º ë‹µë³€ ìƒì„±"]
        direction LR
        J[ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±] --> K[LLM ìƒì„±<br/>GPT-4]
        K --> L[âœ… ë‹µë³€]
    end

    Prepare --> Search
    Search --> Generate
    E -.-> H
    I --> J

    %% Subgraph ìŠ¤íƒ€ì¼
    style Prepare fill:#e1f5ff,stroke:#01579b,stroke-width:3px,color:#000
    style Search fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000
    style Generate fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px,color:#000
```

---

## 2. ë¬¸ì„œ ì²˜ë¦¬

### 2.1 í…ìŠ¤íŠ¸ ë¶„í• 

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", ". ", " ", ""]
)

chunks = text_splitter.split_documents(documents)
```

### 2.2 ì„ë² ë”© ìƒì„±

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small"
)

vectors = embeddings.embed_documents([chunk.page_content for chunk in chunks])
```

---

## 3. Vector Store

### 3.1 pgvector ì—°ë™

```python
from langchain_postgres.vectorstores import PGVector

vectorstore = PGVector(
    collection_name="paper_chunks",
    embedding_function=embeddings,
    connection_string="postgresql://user:password@localhost:5432/papers"
)

# ë¬¸ì„œ ì¶”ê°€
vectorstore.add_documents(chunks)
```

### 3.2 ê²€ìƒ‰

```python
# Similarity Search
docs = vectorstore.similarity_search(query, k=5)

# MMR (Maximal Marginal Relevance)
docs = vectorstore.max_marginal_relevance_search(query, k=5, fetch_k=20)
```

---

## 4. Retriever

### 4.1 ê¸°ë³¸ Retriever

```python
retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 5, "fetch_k": 20}
)

docs = retriever.invoke(query)
```

### 4.2 MultiQueryRetriever

```python
from langchain.retrievers import MultiQueryRetriever

retriever = MultiQueryRetriever.from_llm(
    retriever=vectorstore.as_retriever(),
    llm=llm
)
```

---

## 5. ìš©ì–´ì§‘ í†µí•©

### 5.1 ìš©ì–´ì§‘ ê²€ìƒ‰

```python
# ìš©ì–´ì§‘ ì „ìš© Vector Store
glossary_store = PGVector(
    collection_name="glossary_embeddings",
    embedding_function=embeddings,
    connection_string=CONNECTION_STRING
)

# ìš©ì–´ ê²€ìƒ‰
glossary_docs = glossary_store.similarity_search(term, k=3)
```

### 5.2 í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

```python
def hybrid_search(query, difficulty="easy"):
    """ìš©ì–´ì§‘ + ë…¼ë¬¸ ë³¸ë¬¸ ë™ì‹œ ê²€ìƒ‰"""
    # ìš©ì–´ì§‘ ê²€ìƒ‰
    glossary_results = glossary_store.similarity_search(query, k=2)
    
    # ë…¼ë¬¸ ê²€ìƒ‰
    paper_results = vectorstore.similarity_search(query, k=3)
    
    # ê²°í•©
    combined_context = "### ìš©ì–´:\n" + glossary_results + "\n### ë…¼ë¬¸:\n" + paper_results
    
    return combined_context
```

---

## 6. í”„ë¡¬í”„íŠ¸ êµ¬ì„±

```python
RAG_PROMPT = """
ë‹¹ì‹ ì€ ë…¼ë¬¸ ë¦¬ë·° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì°¸ê³  ë…¼ë¬¸]
{context}

[ì§ˆë¬¸]
{question}

[ë‹µë³€ ê·œì¹™]
- ì°¸ê³  ë…¼ë¬¸ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
- ì¶œì²˜ë¥¼ ëª…ì‹œ (ë…¼ë¬¸ ì œëª©, ì €ì)
- ë…¼ë¬¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ ê²ƒ
- ë‚œì´ë„: {difficulty}

ë‹µë³€:
"""
```

---

## 7. ì°¸ê³  ìë£Œ

- Langchain RAG: https://python.langchain.com/docs/tutorials/rag/
- Langchain VectorStores: https://python.langchain.com/docs/integrations/vectorstores/
