# 11. 데이터베이스 설계

## 문서 정보
- **작성일**: 2025-10-30
- **프로젝트명**: 논문 리뷰 챗봇 (AI Agent + RAG)
- **팀명**: 연결의 민족

---

## 1. 데이터베이스 아키텍처

### 1.1 전체 구조

**선택:** PostgreSQL + pgvector 통합 솔루션

**이유:**
- 관계형 데이터와 벡터 검색을 하나의 DB에서 처리
- 운영 및 유지보수 간소화
- Langchain과 완벽한 통합

---

## 2. PostgreSQL 스키마

### 2.1 papers 테이블 (논문 메타데이터)

```sql
CREATE TABLE papers (
    paper_id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    authors TEXT,                          -- JSON 또는 TEXT 형식
    publish_date DATE,
    source VARCHAR(100),                   -- 'arXiv', 'IEEE', 'ACL' 등
    url TEXT UNIQUE,                       -- 논문 URL (중복 방지)
    category VARCHAR(100),                 -- 'cs.AI', 'cs.CL', 'cs.CV' 등
    citation_count INT DEFAULT 0,
    abstract TEXT,                         -- 논문 초록
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스 생성
CREATE INDEX idx_papers_title ON papers USING GIN (to_tsvector('english', title));
CREATE INDEX idx_papers_category ON papers(category);
CREATE INDEX idx_papers_publish_date ON papers(publish_date DESC);
CREATE INDEX idx_papers_created_at ON papers(created_at DESC);
```

### 2.2 glossary 테이블 (용어집)

```sql
CREATE TABLE glossary (
    term_id SERIAL PRIMARY KEY,
    term VARCHAR(200) NOT NULL UNIQUE,     -- 용어
    definition TEXT NOT NULL,              -- 기본 정의
    easy_explanation TEXT,                 -- Easy 모드 설명
    hard_explanation TEXT,                 -- Hard 모드 설명
    category VARCHAR(100),                 -- 'ML', 'NLP', 'CV', 'RL' 등
    difficulty_level VARCHAR(20),          -- 'beginner', 'intermediate', 'advanced'
    related_terms TEXT[],                  -- 관련 용어 배열
    examples TEXT,                         -- 사용 예시
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX idx_glossary_term ON glossary(term);
CREATE INDEX idx_glossary_category ON glossary(category);
CREATE INDEX idx_glossary_difficulty ON glossary(difficulty_level);
```

### 2.3 query_logs 테이블 (사용자 질의 로그)

```sql
CREATE TABLE query_logs (
    log_id SERIAL PRIMARY KEY,
    user_query TEXT NOT NULL,              -- 사용자 질문
    difficulty_mode VARCHAR(20),           -- 'easy' 또는 'hard'
    tool_used VARCHAR(50),                 -- 사용된 도구명
    response TEXT,                         -- 생성된 응답
    response_time_ms INT,                  -- 응답 시간 (밀리초)
    success BOOLEAN DEFAULT TRUE,          -- 성공 여부
    error_message TEXT,                    -- 오류 메시지 (있는 경우)
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX idx_query_logs_created_at ON query_logs(created_at DESC);
CREATE INDEX idx_query_logs_tool_used ON query_logs(tool_used);
CREATE INDEX idx_query_logs_success ON query_logs(success);
```

---

## 3. pgvector 컬렉션

### 3.1 컬렉션 구조

**3개의 pgvector 컬렉션:**

1. **paper_chunks**: 논문 본문 청크
2. **paper_abstracts**: 논문 초록
3. **glossary_embeddings**: 용어집 임베딩

### 3.2 Langchain PGVector 설정

```python
from langchain_postgres.vectorstores import PGVector
from langchain_openai import OpenAIEmbeddings

# 임베딩 모델
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# 연결 문자열
CONNECTION_STRING = "postgresql://user:password@localhost:5432/papers"

# 1. 논문 본문 컬렉션
paper_chunks_store = PGVector(
    collection_name="paper_chunks",
    embedding_function=embeddings,
    connection_string=CONNECTION_STRING
)

# 2. 논문 초록 컬렉션
abstract_store = PGVector(
    collection_name="paper_abstracts",
    embedding_function=embeddings,
    connection_string=CONNECTION_STRING
)

# 3. 용어집 컬렉션
glossary_store = PGVector(
    collection_name="glossary_embeddings",
    embedding_function=embeddings,
    connection_string=CONNECTION_STRING
)
```

---

## 4. 데이터 흐름

### 4.1 논문 데이터 저장 흐름

```
1. arXiv API로 논문 메타데이터 수집
2. PostgreSQL papers 테이블에 메타데이터 저장 (paper_id 반환)
3. PDF 다운로드 및 텍스트 추출
4. RecursiveCharacterTextSplitter로 청크 분할
5. OpenAI Embeddings로 임베딩 생성
6. pgvector paper_chunks 컬렉션에 저장 (paper_id 메타데이터 포함)
```

### 4.2 검색 흐름

```
1. 사용자 질문 임베딩 생성
2. pgvector similarity_search로 관련 청크 검색 (Top-K)
3. 청크의 paper_id로 PostgreSQL papers 테이블 조회
4. 메타데이터 (제목, 저자, 년도) + 청크 내용을 LLM에 전달
5. LLM이 답변 생성
```

---

## 5. 샘플 데이터

### 5.1 papers 테이블

```sql
INSERT INTO papers (title, authors, publish_date, source, url, category, abstract)
VALUES (
    'Attention Is All You Need',
    'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin',
    '2017-06-12',
    'arXiv',
    'https://arxiv.org/abs/1706.03762',
    'cs.CL',
    'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...'
);
```

### 5.2 glossary 테이블

```sql
INSERT INTO glossary (term, definition, easy_explanation, hard_explanation, category, difficulty_level)
VALUES (
    'Attention Mechanism',
    'A technique that allows models to focus on specific parts of the input when generating output.',
    '책을 읽을 때 중요한 부분에 집중하는 것처럼, AI가 입력 데이터에서 중요한 부분에 집중하는 기술입니다.',
    'A weighted sum mechanism that computes attention scores between query and key vectors using dot-product similarity, allowing the model to dynamically focus on relevant input positions during sequence processing.',
    'Deep Learning',
    'intermediate'
);
```

---

## 6. 초기화 스크립트

### 6.1 database/schema.sql

```sql
-- pgvector 확장 활성화
CREATE EXTENSION IF NOT EXISTS vector;

-- papers 테이블 생성
CREATE TABLE IF NOT EXISTS papers (
    paper_id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    authors TEXT,
    publish_date DATE,
    source VARCHAR(100),
    url TEXT UNIQUE,
    category VARCHAR(100),
    citation_count INT DEFAULT 0,
    abstract TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX IF NOT EXISTS idx_papers_title ON papers USING GIN (to_tsvector('english', title));
CREATE INDEX IF NOT EXISTS idx_papers_category ON papers(category);
CREATE INDEX IF NOT EXISTS idx_papers_publish_date ON papers(publish_date DESC);

-- glossary 테이블 생성
CREATE TABLE IF NOT EXISTS glossary (
    term_id SERIAL PRIMARY KEY,
    term VARCHAR(200) NOT NULL UNIQUE,
    definition TEXT NOT NULL,
    easy_explanation TEXT,
    hard_explanation TEXT,
    category VARCHAR(100),
    difficulty_level VARCHAR(20),
    related_terms TEXT[],
    examples TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX IF NOT EXISTS idx_glossary_term ON glossary(term);
CREATE INDEX IF NOT EXISTS idx_glossary_category ON glossary(category);

-- query_logs 테이블 생성
CREATE TABLE IF NOT EXISTS query_logs (
    log_id SERIAL PRIMARY KEY,
    user_query TEXT NOT NULL,
    difficulty_mode VARCHAR(20),
    tool_used VARCHAR(50),
    response TEXT,
    response_time_ms INT,
    success BOOLEAN DEFAULT TRUE,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 인덱스
CREATE INDEX IF NOT EXISTS idx_query_logs_created_at ON query_logs(created_at DESC);
CREATE INDEX IF NOT EXISTS idx_query_logs_tool_used ON query_logs(tool_used);
```

### 6.2 실행

```bash
psql -U your_username -d papers -f database/schema.sql
```

---

## 7. 백업 및 복구

### 7.1 백업

```bash
# 전체 데이터베이스 백업
pg_dump -U your_username -d papers -F c -f backup_$(date +%Y%m%d).dump

# 특정 테이블만 백업
pg_dump -U your_username -d papers -t papers -F c -f papers_backup.dump
```

### 7.2 복구

```bash
# 데이터베이스 복원
createdb papers_restored
pg_restore -U your_username -d papers_restored backup_20251030.dump
```

---

## 8. 참고 자료

- PostgreSQL 공식 문서: https://www.postgresql.org/docs/
- pgvector GitHub: https://github.com/pgvector/pgvector
- Langchain PGVector: https://python.langchain.com/docs/integrations/vectorstores/pgvector
