# ìë£Œì¡°ì‚¬: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

## ë¬¸ì„œ ì •ë³´
- **ì‘ì„±ì¼**: 2025-10-29
- **í”„ë¡œì íŠ¸**: ë…¼ë¬¸ ë¦¬ë·° ì±—ë´‡ (AI Agent + RAG)
- **íŒ€ëª…**: ì—°ê²°ì˜ ë¯¼ì¡±

---

## 1. ì‹œìŠ¤í…œ ê°œìš”

ë…¼ë¬¸ ë¦¬ë·° ì±—ë´‡ì€ **AI Agent**ì™€ **RAG (Retrieval-Augmented Generation)**ë¥¼ ê²°í•©í•˜ì—¬, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì§€ëŠ¥ì ìœ¼ë¡œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ë‚œì´ë„ë³„(Easy/Hard) ë§ì¶¤ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### 1.1 í•µì‹¬ ê¸°ëŠ¥

1. **ì§€ëŠ¥í˜• ë¼ìš°íŒ…**: ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì¼ë°˜ ë‹µë³€, RAG ê²€ìƒ‰, ì›¹ ê²€ìƒ‰ ìë™ ì„ íƒ
2. **ë…¼ë¬¸ ê²€ìƒ‰ ë° ìš”ì•½**: ë¡œì»¬ DBì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰ ë° ë‚œì´ë„ë³„ ìš”ì•½ ì œê³µ
3. **ìš©ì–´ì§‘ ê´€ë¦¬**: ì „ë¬¸ ìš©ì–´ ìë™ ì„¤ëª…
4. **ì›¹ ê²€ìƒ‰**: ìµœì‹  ë…¼ë¬¸ ì •ë³´ ê²€ìƒ‰
5. **íŒŒì¼ ì €ì¥**: ëŒ€í™” ë‚´ìš© ë° ìš”ì•½ ì €ì¥
6. **ë‚œì´ë„ë³„ ë‹µë³€**: Easy ëª¨ë“œ(ì´ˆì‹¬ì), Hard ëª¨ë“œ(ì „ë¬¸ê°€)

---

## 2. ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 2.1 High-Level Architecture

```mermaid
graph TB
    subgraph UserInterface["ğŸ”¸ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤"]
        direction LR
        User[ì‚¬ìš©ì] --> UI[Streamlit UI<br/>ğŸ“± ì±„íŒ… ì¸í„°í˜ì´ìŠ¤]
        UI --> Agent[AI Agent<br/>âš™ï¸ LangGraph]
    end

    subgraph AgentCore["ğŸ”¹ AI Agent ë¼ìš°íŒ…"]
        direction TB
        Agent --> Router{ë¼ìš°í„° ë…¸ë“œ<br/>ì§ˆë¬¸ ë¶„ì„}
        Router -->|ì¼ë°˜ ì§ˆë¬¸| General[ì¼ë°˜ ë‹µë³€ ë„êµ¬]
        Router -->|ë…¼ë¬¸ ê²€ìƒ‰| RAG[RAG ê²€ìƒ‰ ë„êµ¬]
        Router -->|ìµœì‹  ì •ë³´| Web[ì›¹ ê²€ìƒ‰ ë„êµ¬]
        Router -->|ìš©ì–´ ì§ˆë¬¸| Glossary[ìš©ì–´ì§‘ ë„êµ¬]
        Router -->|ìš”ì•½ ìš”ì²­| Summarize[ë…¼ë¬¸ ìš”ì•½ ë„êµ¬]
        Router -->|ì €ì¥ ìš”ì²­| Save[íŒŒì¼ ì €ì¥ ë„êµ¬]
    end

    subgraph DataLayer["ğŸ”º ë°ì´í„° & LLM ë ˆì´ì–´"]
        direction TB
        VectorDB[(ğŸ’¾ Vector DB<br/>ChromaDB)]
        PostgreSQL[(ğŸ’¾ PostgreSQL<br/>ë©”íƒ€ë°ì´í„°)]
        TavilyAPI[ğŸ” Tavily Search<br/>ì›¹ ê²€ìƒ‰ API]
        LLM[ğŸ¤– OpenAI GPT-4<br/>ë‹µë³€ ìƒì„±]
    end

    %% ë„êµ¬ì™€ ë°ì´í„° ì—°ê²°
    RAG --> VectorDB
    RAG --> PostgreSQL
    Glossary --> PostgreSQL
    Glossary --> VectorDB
    Web --> TavilyAPI

    %% ë„êµ¬ì™€ LLM ì—°ê²°
    General --> LLM
    RAG --> LLM
    Web --> LLM
    Glossary --> LLM
    Summarize --> LLM

    %% ì‘ë‹µ ê²½ë¡œ
    LLM --> Response[âœ… ìµœì¢… ë‹µë³€<br/>ë‚œì´ë„ ì ìš©]
    Response --> UI

    %% Subgraph ìŠ¤íƒ€ì¼
    style UserInterface fill:#e1f5ff,stroke:#01579b,stroke-width:3px,color:#000
    style AgentCore fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000
    style DataLayer fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ - íŒŒë‘ ê³„ì—´)
    style User fill:#90caf9,stroke:#1976d2,color:#000
    style UI fill:#64b5f6,stroke:#1976d2,color:#000
    style Agent fill:#42a5f5,stroke:#1565c0,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (AI Agent - ë³´ë¼ ê³„ì—´)
    style Router fill:#ba68c8,stroke:#7b1fa2,color:#fff
    style General fill:#ce93d8,stroke:#7b1fa2,color:#000
    style RAG fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Web fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Glossary fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Summarize fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Save fill:#ce93d8,stroke:#7b1fa2,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ë°ì´í„° & LLM - ë…¹ìƒ‰ ê³„ì—´)
    style VectorDB fill:#a5d6a7,stroke:#388e3c,color:#000
    style PostgreSQL fill:#a5d6a7,stroke:#388e3c,color:#000
    style TavilyAPI fill:#81c784,stroke:#2e7d32,color:#000
    style LLM fill:#66bb6a,stroke:#2e7d32,color:#fff
    style Response fill:#4caf50,stroke:#1b5e20,color:#fff
```

---

### 2.2 ìƒì„¸ ë°ì´í„° íë¦„

```mermaid
sequenceDiagram
    participant U as ì‚¬ìš©ì
    participant UI as Streamlit UI
    participant A as AI Agent
    participant R as ë¼ìš°í„°
    participant RAG as RAG ë„êµ¬
    participant VDB as Vector DB
    participant PG as PostgreSQL
    participant LLM as OpenAI GPT-4

    U->>UI: ì§ˆë¬¸ ì…ë ¥ + ë‚œì´ë„ ì„ íƒ
    UI->>A: ì§ˆë¬¸ ì „ë‹¬
    A->>R: ì§ˆë¬¸ ë¶„ì„ ìš”ì²­

    alt ë…¼ë¬¸ ê²€ìƒ‰ ì§ˆë¬¸
        R->>RAG: search_paper_database(query)
        RAG->>VDB: ìœ ì‚¬ë„ ê²€ìƒ‰ (Top-K)
        VDB-->>RAG: ê´€ë ¨ ë…¼ë¬¸ ì²­í¬
        RAG->>PG: ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        PG-->>RAG: ì œëª©, ì €ì, ë…„ë„
        RAG->>LLM: í”„ë¡¬í”„íŠ¸ + ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
        LLM-->>RAG: ë‹µë³€ ìƒì„±
        RAG-->>A: ë‹µë³€ ë°˜í™˜
    else ìš©ì–´ ì§ˆë¬¸
        R->>Glossary: search_glossary(term)
        Glossary->>PG: ìš©ì–´ ì •ì˜ ì¡°íšŒ
        PG-->>Glossary: ì •ì˜ í…ìŠ¤íŠ¸
        Glossary->>LLM: ë‚œì´ë„ë³„ ì„¤ëª… ìš”ì²­
        LLM-->>Glossary: ì„¤ëª… ìƒì„±
        Glossary-->>A: ë‹µë³€ ë°˜í™˜
    else ìµœì‹  ë…¼ë¬¸ ì§ˆë¬¸
        R->>Web: web_search(query)
        Web->>TavilyAPI: ê²€ìƒ‰ ìš”ì²­
        TavilyAPI-->>Web: ê²€ìƒ‰ ê²°ê³¼
        Web->>LLM: ê²°ê³¼ ì •ë¦¬ ìš”ì²­
        LLM-->>Web: ì •ë¦¬ëœ ë‹µë³€
        Web-->>A: ë‹µë³€ ë°˜í™˜
    end

    A->>UI: ìµœì¢… ë‹µë³€ ì „ë‹¬
    UI->>U: ë‹µë³€ í‘œì‹œ
```

---

## 3. ì»´í¬ë„ŒíŠ¸ë³„ ìƒì„¸ ì„¤ê³„

### 3.1 UI Layer (Streamlit)

**ì—­í• :**
- ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ì œê³µ
- ë‚œì´ë„ ì„ íƒ (Easy/Hard)
- ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥

**ì£¼ìš” ê¸°ëŠ¥:**
```python
# ui/app.py

import streamlit as st

# ë‚œì´ë„ ì„ íƒ
difficulty = st.selectbox(
    "ë‹µë³€ ë‚œì´ë„",
    ["Easy ëª¨ë“œ (ì´ˆì‹¬ììš©)", "Hard ëª¨ë“œ (ì „ë¬¸ê°€ìš©)"]
)

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

# ë©”ì‹œì§€ í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("ë…¼ë¬¸ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”"):
    # Agent í˜¸ì¶œ
    response = agent_executor.invoke({
        "question": prompt,
        "difficulty": "easy" if "Easy" in difficulty else "hard"
    })
```

---

### 3.2 AI Agent Layer (LangGraph)

**ì—­í• :**
- ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„
- ì ì ˆí•œ ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰
- ë„êµ¬ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±

**ê·¸ë˜í”„ êµ¬ì¡°:**

```mermaid
graph LR
    START([ğŸ”¸ ì‹œì‘<br/>ì§ˆë¬¸ ì…ë ¥]) --> Router{ë¼ìš°í„° ë…¸ë“œ<br/>ì§ˆë¬¸ ë¶„ì„}

    Router -->|ì¼ë°˜ ì§ˆë¬¸| General[ì¼ë°˜ ë‹µë³€<br/>ì§ì ‘ ì‘ë‹µ]
    Router -->|ë…¼ë¬¸ ê²€ìƒ‰| RAG[RAG ê²€ìƒ‰<br/>DB ì¡°íšŒ]
    Router -->|ì›¹ ê²€ìƒ‰| Web[ì›¹ ê²€ìƒ‰<br/>ìµœì‹  ì •ë³´]
    Router -->|ìš©ì–´ ì§ˆë¬¸| Glossary[ìš©ì–´ì§‘<br/>ì •ì˜ ì„¤ëª…]
    Router -->|ìš”ì•½ ìš”ì²­| Summarize[ë…¼ë¬¸ ìš”ì•½<br/>ë‚œì´ë„ ì ìš©]
    Router -->|ì €ì¥ ìš”ì²­| Save[íŒŒì¼ ì €ì¥<br/>ğŸ’¾ ë‹¤ìš´ë¡œë“œ]

    General --> END([âœ… ì¢…ë£Œ<br/>ë‹µë³€ ì „ë‹¬])
    RAG --> END
    Web --> END
    Glossary --> END
    Summarize --> END
    Save --> END

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼
    style START fill:#81c784,stroke:#388e3c,stroke-width:2px,color:#000
    style END fill:#66bb6a,stroke:#2e7d32,stroke-width:2px,color:#fff
    style Router fill:#ba68c8,stroke:#7b1fa2,stroke-width:2px,color:#fff

    %% ë„êµ¬ ë…¸ë“œ ìŠ¤íƒ€ì¼ (ë³´ë¼ ê³„ì—´)
    style General fill:#ce93d8,stroke:#7b1fa2,color:#000
    style RAG fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Web fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Glossary fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Summarize fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Save fill:#ce93d8,stroke:#7b1fa2,color:#000
```

**êµ¬í˜„ ì½”ë“œ:**
```python
# src/agent/graph.py

from langgraph.graph import StateGraph, END
from typing import TypedDict

class AgentState(TypedDict):
    question: str
    difficulty: str
    tool_choice: str
    tool_result: str
    final_answer: str

def router_node(state: AgentState):
    """
    ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ê²°ì •
    """
    question = state["question"]

    # LLMì—ê²Œ ë¼ìš°íŒ… ê²°ì • ìš”ì²­
    routing_prompt = f"""
    ì‚¬ìš©ì ì§ˆë¬¸: {question}

    ë‹¤ìŒ ì¤‘ ê°€ì¥ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:
    - search_paper: ë…¼ë¬¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰
    - web_search: ìµœì‹  ì •ë³´ ì›¹ ê²€ìƒ‰
    - glossary: ìš©ì–´ ì •ì˜ ê²€ìƒ‰
    - summarize: ë…¼ë¬¸ ìš”ì•½
    - save_file: íŒŒì¼ ì €ì¥
    - general: ì¼ë°˜ ë‹µë³€

    ë„êµ¬:
    """

    tool_choice = llm.invoke(routing_prompt).strip()
    state["tool_choice"] = tool_choice

    return state

def conditional_edge(state: AgentState):
    """ë¼ìš°íŒ… ê²°ì •ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ì„ íƒ"""
    return state["tool_choice"]

# ê·¸ë˜í”„ êµ¬ì„±
workflow = StateGraph(AgentState)

workflow.add_node("router", router_node)
workflow.add_node("search_paper", search_paper_node)
workflow.add_node("web_search", web_search_node)
workflow.add_node("glossary", glossary_node)
workflow.add_node("summarize", summarize_node)
workflow.add_node("save_file", save_file_node)
workflow.add_node("general", general_node)

workflow.set_entry_point("router")

workflow.add_conditional_edges(
    "router",
    conditional_edge,
    {
        "search_paper": "search_paper",
        "web_search": "web_search",
        "glossary": "glossary",
        "summarize": "summarize",
        "save_file": "save_file",
        "general": "general"
    }
)

# ëª¨ë“  ë…¸ë“œì—ì„œ ì¢…ë£Œ
for node in ["search_paper", "web_search", "glossary", "summarize", "save_file", "general"]:
    workflow.add_edge(node, END)

agent_executor = workflow.compile()
```

---

### 3.3 Tools Layer

**ì—­í• :**
- ê° ë„êµ¬ë³„ êµ¬ì²´ì ì¸ ê¸°ëŠ¥ êµ¬í˜„
- ì™¸ë¶€ API ë° DB ì—°ë™

#### ë„êµ¬ 1: RAG ê²€ìƒ‰ ë„êµ¬

```python
# src/tools/rag_search.py

from langchain.tools import tool

@tool
def search_paper_database(query: str) -> str:
    """ë…¼ë¬¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # 1. Vector DBì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰
    docs = vectorstore.similarity_search(query, k=5)

    # 2. PostgreSQLì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    results = []
    for doc in docs:
        paper_id = doc.metadata['paper_id']
        meta = get_paper_metadata(paper_id)  # PostgreSQL ì¡°íšŒ
        results.append({
            'title': meta['title'],
            'authors': meta['authors'],
            'year': meta['year'],
            'content': doc.page_content
        })

    return format_search_results(results)
```

#### ë„êµ¬ 2: ì›¹ ê²€ìƒ‰ ë„êµ¬

```python
# src/tools/web_search.py

from langchain.tools import TavilySearchResults

web_search_tool = TavilySearchResults(
    max_results=5,
    search_depth="advanced",
    include_answer=True
)
```

#### ë„êµ¬ 3: ìš©ì–´ì§‘ ë„êµ¬

```python
# src/tools/glossary.py

@tool
def search_glossary(term: str, difficulty: str = "easy") -> str:
    """ë…¼ë¬¸ ìš©ì–´ì§‘ì—ì„œ ìš©ì–´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # PostgreSQL ìš©ì–´ì§‘ í…Œì´ë¸” ì¡°íšŒ
    result = db.execute(
        "SELECT term, easy_explanation, hard_explanation FROM glossary WHERE term ILIKE %s",
        (f"%{term}%",)
    ).fetchone()

    if result:
        explanation = result['easy_explanation'] if difficulty == "easy" else result['hard_explanation']
        return f"**{result['term']}**: {explanation}"
    else:
        # ìš©ì–´ì§‘ì— ì—†ìœ¼ë©´ RAG ê²€ìƒ‰
        return search_paper_database(f"{term} ì •ì˜")
```

---

### 3.4 RAG Layer

**ì—­í• :**
- ë¬¸ì„œ ì„ë² ë”© ë° ê²€ìƒ‰
- ê²€ìƒ‰ ê²°ê³¼ ì¬ìˆœìœ„í™” (Reranking)
- ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±

**ì»´í¬ë„ŒíŠ¸:**

```mermaid
graph TB
    subgraph InputProcess["ğŸ”¸ ì§ˆë¬¸ ì²˜ë¦¬"]
        direction LR
        Query[ì‚¬ìš©ì ì§ˆë¬¸<br/>ì…ë ¥] --> Embed[ì§ˆë¬¸ ì„ë² ë”©<br/>ë²¡í„° ë³€í™˜]
        Embed --> Search[ìœ ì‚¬ë„ ê²€ìƒ‰<br/>Cosine Similarity]
    end

    subgraph Retrieval["ğŸ”¹ ë¬¸ì„œ ê²€ìƒ‰ & ì¬ìˆœìœ„í™”"]
        direction LR
        VDB[(ğŸ’¾ Vector DB<br/>ChromaDB)] --> TopK[Top-K ë¬¸ì„œ<br/>ìƒìœ„ 5ê°œ]
        TopK --> Rerank{Reranking?<br/>ì„ íƒ ì‚¬í•­}
        Rerank -->|Yes| Context1[ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±<br/>ì¬ì •ë ¬ ì ìš©]
        Rerank -->|No| Context2[ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±<br/>ì›ë³¸ ìˆœì„œ]
        Context1 --> Context[ìµœì¢… ì»¨í…ìŠ¤íŠ¸]
        Context2 --> Context
    end

    subgraph Generation["ğŸ”º ë‹µë³€ ìƒì„±"]
        direction LR
        Prompt[LLM í”„ë¡¬í”„íŠ¸<br/>ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸] --> LLM[ğŸ¤– OpenAI GPT-4<br/>ë‹µë³€ ìƒì„±]
        LLM --> Answer[âœ… ìµœì¢… ë‹µë³€<br/>ì‚¬ìš©ì ì „ë‹¬]
    end

    %% ë‹¨ê³„ ê°„ ì—°ê²°
    InputProcess --> Retrieval
    Search --> VDB
    Retrieval --> Generation
    Context --> Prompt

    %% Subgraph ìŠ¤íƒ€ì¼
    style InputProcess fill:#e1f5ff,stroke:#01579b,stroke-width:3px,color:#000
    style Retrieval fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000
    style Generation fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ì§ˆë¬¸ ì²˜ë¦¬ - íŒŒë‘ ê³„ì—´)
    style Query fill:#90caf9,stroke:#1976d2,color:#000
    style Embed fill:#64b5f6,stroke:#1976d2,color:#000
    style Search fill:#42a5f5,stroke:#1565c0,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ê²€ìƒ‰ - ë³´ë¼ ê³„ì—´)
    style VDB fill:#ce93d8,stroke:#7b1fa2,color:#000
    style TopK fill:#ba68c8,stroke:#7b1fa2,color:#fff
    style Rerank fill:#ba68c8,stroke:#7b1fa2,color:#fff
    style Context1 fill:#ab47bc,stroke:#4a148c,color:#fff
    style Context2 fill:#ab47bc,stroke:#4a148c,color:#fff
    style Context fill:#9c27b0,stroke:#4a148c,color:#fff

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ë‹µë³€ ìƒì„± - ë…¹ìƒ‰ ê³„ì—´)
    style Prompt fill:#a5d6a7,stroke:#388e3c,color:#000
    style LLM fill:#81c784,stroke:#2e7d32,color:#000
    style Answer fill:#66bb6a,stroke:#2e7d32,color:#fff
```

**êµ¬í˜„:**
```python
# src/rag/retriever.py

from langchain.vectorstores import Chroma
from langchain.retrievers import ContextualCompressionRetriever

class PaperRetriever:
    def __init__(self, vectorstore, embeddings):
        self.vectorstore = vectorstore
        self.embeddings = embeddings

    def retrieve(self, query: str, k: int = 5):
        """ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰"""
        docs = self.vectorstore.similarity_search(query, k=k)
        return docs

    def retrieve_with_rerank(self, query: str, k: int = 5):
        """Rerankingì„ í¬í•¨í•œ ê²€ìƒ‰"""
        # ë¨¼ì € k*2 ê°œ í›„ë³´ ì¡°íšŒ
        docs = self.vectorstore.similarity_search(query, k=k*2)

        # Reranking (Cohere ë˜ëŠ” ìì²´ êµ¬í˜„)
        reranked_docs = self.rerank(query, docs)

        return reranked_docs[:k]
```

---

### 3.5 Database Layer

**ì—­í• :**
- ë°ì´í„° ì˜êµ¬ ì €ì¥
- ë©”íƒ€ë°ì´í„° ê´€ë¦¬
- ì„ë² ë”© ë²¡í„° ì €ì¥

#### PostgreSQL ìŠ¤í‚¤ë§ˆ

```sql
-- ë…¼ë¬¸ ë©”íƒ€ë°ì´í„° í…Œì´ë¸”
CREATE TABLE papers (
    paper_id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    authors TEXT,
    publish_date DATE,
    source VARCHAR(100),
    url TEXT UNIQUE,
    category VARCHAR(100),
    citation_count INT DEFAULT 0,
    abstract TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ìš©ì–´ì§‘ í…Œì´ë¸”
CREATE TABLE glossary (
    term_id SERIAL PRIMARY KEY,
    term VARCHAR(200) NOT NULL UNIQUE,
    definition TEXT NOT NULL,
    easy_explanation TEXT,
    hard_explanation TEXT,
    category VARCHAR(100),
    difficulty_level VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì‚¬ìš©ì ì§ˆì˜ ë¡œê·¸ í…Œì´ë¸”
CREATE TABLE query_logs (
    log_id SERIAL PRIMARY KEY,
    user_query TEXT NOT NULL,
    difficulty_mode VARCHAR(20),
    tool_used VARCHAR(50),
    response_time_ms INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_papers_title ON papers USING GIN (to_tsvector('english', title));
CREATE INDEX idx_papers_category ON papers(category);
CREATE INDEX idx_glossary_term ON glossary(term);
```

#### Vector DB ì»¬ë ‰ì…˜

```python
# data/vectordb/ êµ¬ì¡°

vectordb/
â”œâ”€â”€ paper_chunks/        # ë…¼ë¬¸ ë³¸ë¬¸ ì²­í¬
â”œâ”€â”€ paper_abstracts/     # ë…¼ë¬¸ ì´ˆë¡
â””â”€â”€ glossary/            # ìš©ì–´ì§‘ ì„ë² ë”©
```

---

### 3.6 LLM Layer

**ì—­í• :**
- ìì—°ì–´ ì´í•´ ë° ìƒì„±
- ë„êµ¬ í˜¸ì¶œ ê²°ì • (Function Calling)
- ë‚œì´ë„ë³„ ë‹µë³€ ìƒì„±

**ëª¨ë¸ ì„ íƒ:**
- **GPT-4**: ë³µì¡í•œ ì¶”ë¡ , ë†’ì€ ì •í™•ë„ í•„ìš” ì‹œ
- **GPT-3.5-turbo**: ë¹„ìš© íš¨ìœ¨ì , ë¹ ë¥¸ ì‘ë‹µ

**í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:**

```python
# src/prompts/templates.py

EASY_MODE_PROMPT = """
ë‹¹ì‹ ì€ AI ì´ˆì‹¬ìë¥¼ ìœ„í•œ ë…¼ë¬¸ ë¦¬ë·° ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ë‹µë³€ ê·œì¹™:
1. ì „ë¬¸ ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…
2. ì‹¤ìƒí™œ ë¹„ìœ  ì‚¬ìš©
3. ìˆ˜ì‹ì€ ìµœì†Œí™”
4. í•µì‹¬ ì•„ì´ë””ì–´ 3ê°€ì§€ ì´ë‚´ë¡œ ìš”ì•½

ì»¨í…ìŠ¤íŠ¸: {context}
ì§ˆë¬¸: {question}

ë‹µë³€:
"""

HARD_MODE_PROMPT = """
ë‹¹ì‹ ì€ AI ì „ë¬¸ê°€ë¥¼ ìœ„í•œ ë…¼ë¬¸ ë¦¬ë·° ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ë‹µë³€ ê·œì¹™:
1. ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ í¬í•¨
2. ìˆ˜ì‹ ë° ì•Œê³ ë¦¬ì¦˜ ì„¤ëª…
3. ê´€ë ¨ ë…¼ë¬¸ ë¹„êµ
4. êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

ì»¨í…ìŠ¤íŠ¸: {context}
ì§ˆë¬¸: {question}

ë‹µë³€:
"""
```

---

## 4. ëª¨ë“ˆ êµ¬ì¡°

### 4.1 ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
langchain-project/
â”œâ”€â”€ main.py                    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py                 # Streamlit UI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ graph.py           # LangGraph ê·¸ë˜í”„ ì •ì˜
â”‚   â”‚   â”œâ”€â”€ nodes.py           # ë…¸ë“œ í•¨ìˆ˜ë“¤
â”‚   â”‚   â””â”€â”€ state.py           # State ì •ì˜
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ rag_search.py      # RAG ê²€ìƒ‰ ë„êµ¬
â”‚   â”‚   â”œâ”€â”€ web_search.py      # ì›¹ ê²€ìƒ‰ ë„êµ¬
â”‚   â”‚   â”œâ”€â”€ glossary.py        # ìš©ì–´ì§‘ ë„êµ¬
â”‚   â”‚   â”œâ”€â”€ summarize.py       # ìš”ì•½ ë„êµ¬
â”‚   â”‚   â””â”€â”€ file_save.py       # íŒŒì¼ ì €ì¥ ë„êµ¬
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ retriever.py       # ë¬¸ì„œ ê²€ìƒ‰
â”‚   â”‚   â”œâ”€â”€ embeddings.py      # ì„ë² ë”© ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ vector_store.py    # Vector DB ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ client.py          # OpenAI í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â””â”€â”€ config.py          # LLM ì„¤ì •
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ templates.py       # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â””â”€â”€ chat_history.py    # ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py          # ë¡œê¹…
â”‚       â””â”€â”€ db.py              # DB ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ processed/             # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”œâ”€â”€ vectordb/              # Vector DB
â”‚   â””â”€â”€ rdbms/                 # PostgreSQL ë°±ì—…
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ db_config.yaml         # DB ì„¤ì •
â”‚   â””â”€â”€ model_config.yaml      # ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ collect_papers.py      # ë…¼ë¬¸ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ preprocess.py          # ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ load_to_db.py          # DB ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”œâ”€â”€ test_rag.py
â”‚   â””â”€â”€ test_tools.py
â””â”€â”€ requirements.txt
```

---

### 4.2 ëª¨ë“ˆ ê°„ ì˜ì¡´ì„±

```mermaid
graph TB
    subgraph Frontend["ğŸ”¸ í”„ë¡ íŠ¸ì—”ë“œ ê³„ì¸µ"]
        direction LR
        UI[ğŸ“± ui/app.py<br/>Streamlit UI] --> Main[âš™ï¸ main.py<br/>ì—”íŠ¸ë¦¬í¬ì¸íŠ¸]
    end

    subgraph CoreLogic["ğŸ”¹ í•µì‹¬ ë¡œì§ ê³„ì¸µ"]
        direction TB
        Agent[ğŸ¤– agent/graph.py<br/>LangGraph]
        Tools[ğŸ”§ tools/*<br/>ë„êµ¬ ëª¨ìŒ]
        LLM[ğŸ’¬ llm/client.py<br/>OpenAI í´ë¼ì´ì–¸íŠ¸]
        Memory[ğŸ’¾ memory/<br/>chat_history.py]
    end

    subgraph DataAccess["ğŸ”º ë°ì´í„° ì ‘ê·¼ ê³„ì¸µ"]
        direction TB
        RAG[ğŸ“Š rag/retriever.py<br/>ë¬¸ì„œ ê²€ìƒ‰]
        VectorStore[ğŸ’¾ rag/vector_store.py<br/>Vector DB]
        Embeddings[ğŸ”¢ rag/embeddings.py<br/>ì„ë² ë”© ê´€ë¦¬]
        DB[ğŸ—„ï¸ utils/db.py<br/>PostgreSQL]
        Prompts[ğŸ“ prompts/templates.py<br/>í”„ë¡¬í”„íŠ¸]
    end

    %% ê³„ì¸µ ê°„ ì—°ê²°
    Frontend --> CoreLogic
    Main --> Agent

    %% í•µì‹¬ ë¡œì§ ë‚´ë¶€ ì—°ê²°
    Agent --> Tools
    Agent --> LLM
    Agent --> Memory

    %% ë°ì´í„° ì ‘ê·¼ ì—°ê²°
    Tools --> RAG
    Tools --> DB
    RAG --> VectorStore
    RAG --> Embeddings
    LLM --> Prompts

    %% Subgraph ìŠ¤íƒ€ì¼
    style Frontend fill:#e1f5ff,stroke:#01579b,stroke-width:3px,color:#000
    style CoreLogic fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000
    style DataAccess fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (í”„ë¡ íŠ¸ì—”ë“œ - íŒŒë‘ ê³„ì—´)
    style UI fill:#90caf9,stroke:#1976d2,color:#000
    style Main fill:#64b5f6,stroke:#1976d2,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (í•µì‹¬ ë¡œì§ - ë³´ë¼ ê³„ì—´)
    style Agent fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Tools fill:#ba68c8,stroke:#7b1fa2,color:#fff
    style LLM fill:#ab47bc,stroke:#4a148c,color:#fff
    style Memory fill:#9c27b0,stroke:#4a148c,color:#fff

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ë°ì´í„° ì ‘ê·¼ - ë…¹ìƒ‰ ê³„ì—´)
    style RAG fill:#a5d6a7,stroke:#388e3c,color:#000
    style VectorStore fill:#81c784,stroke:#2e7d32,color:#000
    style Embeddings fill:#81c784,stroke:#2e7d32,color:#000
    style DB fill:#81c784,stroke:#2e7d32,color:#000
    style Prompts fill:#66bb6a,stroke:#2e7d32,color:#fff
```

---

## 5. ì‹¤í–‰ íë¦„ (Sequence Diagram)

### 5.1 ì¼ë°˜ì ì¸ ì§ˆë¬¸ ì²˜ë¦¬ íë¦„

```mermaid
sequenceDiagram
    autonumber

    participant U as ì‚¬ìš©ì
    participant UI as Streamlit UI
    participant Main as main.py
    participant Agent as AI Agent
    participant Tool as ë„êµ¬ (RAG)
    participant VDB as Vector DB
    participant LLM as OpenAI GPT-4

    U->>UI: "Transformer ë…¼ë¬¸ ì„¤ëª…í•´ì¤˜" + Easy ëª¨ë“œ
    UI->>Main: invoke(question, difficulty="easy")
    Main->>Agent: execute(state)

    Agent->>Agent: ë¼ìš°í„° ë…¸ë“œ: ì§ˆë¬¸ ë¶„ì„
    Agent->>Tool: search_paper_database("Transformer")

    Tool->>VDB: similarity_search("Transformer", k=5)
    VDB-->>Tool: Top-5 ê´€ë ¨ ë¬¸ì„œ
    Tool->>Tool: PostgreSQLì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    Tool-->>Agent: ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜

    Agent->>LLM: í”„ë¡¬í”„íŠ¸ êµ¬ì„±<br/>(ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸ + Easy ëª¨ë“œ)
    LLM-->>Agent: ì´ˆì‹¬ììš© ë‹µë³€ ìƒì„±
    Agent-->>Main: final_answer
    Main-->>UI: ë‹µë³€ ë°˜í™˜
    UI-->>U: ë‹µë³€ í‘œì‹œ
```

---

## 6. ë‚œì´ë„ë³„ ë‹µë³€ ì²˜ë¦¬

### 6.1 ë‚œì´ë„ ëª¨ë“œ íë¦„

```mermaid
graph TB
    subgraph Input["ğŸ”¸ ì§ˆë¬¸ & ë‚œì´ë„ ì„ íƒ"]
        direction LR
        Question[ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥] --> Difficulty{ë‚œì´ë„ ì„ íƒ<br/>Easy / Hard}
    end

    subgraph PromptConfig["ğŸ”¹ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"]
        direction TB
        Difficulty -->|Easy ëª¨ë“œ| EasyPrompt[Easy í”„ë¡¬í”„íŠ¸<br/>âœ… ì‰¬ìš´ ìš©ì–´<br/>âœ… ë¹„ìœ  ì‚¬ìš©<br/>âœ… ìˆ˜ì‹ ìµœì†Œí™”]
        Difficulty -->|Hard ëª¨ë“œ| HardPrompt[Hard í”„ë¡¬í”„íŠ¸<br/>ğŸ”¬ ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­<br/>ğŸ”¬ ìˆ˜ì‹ í¬í•¨<br/>ğŸ”¬ ë…¼ë¬¸ ë¹„êµ]

        EasyPrompt --> Context[ì»¨í…ìŠ¤íŠ¸ í†µí•©<br/>RAG ê²€ìƒ‰ ê²°ê³¼ + í”„ë¡¬í”„íŠ¸]
        HardPrompt --> Context
    end

    subgraph Generation["ğŸ”º ë‹µë³€ ìƒì„± & ì „ë‹¬"]
        direction LR
        Context --> LLM[ğŸ¤– OpenAI GPT-4<br/>ë‹µë³€ ìƒì„±]
        LLM --> Response{ë‹µë³€ íƒ€ì…<br/>ë¶„ê¸°}
        Response -->|Easy| EasyAnswer[ì´ˆì‹¬ììš© ë‹µë³€<br/>ì‰¬ìš´ ì„¤ëª…]
        Response -->|Hard| HardAnswer[ì „ë¬¸ê°€ìš© ë‹µë³€<br/>ê¸°ìˆ ì  ì„¤ëª…]

        EasyAnswer --> User[âœ… ì‚¬ìš©ìì—ê²Œ ì „ë‹¬]
        HardAnswer --> User
    end

    %% ë‹¨ê³„ ê°„ ì—°ê²°
    Input --> PromptConfig
    PromptConfig --> Generation

    %% Subgraph ìŠ¤íƒ€ì¼
    style Input fill:#e1f5ff,stroke:#01579b,stroke-width:3px,color:#000
    style PromptConfig fill:#f3e5f5,stroke:#4a148c,stroke-width:3px,color:#000
    style Generation fill:#e8f5e9,stroke:#1b5e20,stroke-width:3px,color:#000

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ì…ë ¥ - íŒŒë‘ ê³„ì—´)
    style Question fill:#90caf9,stroke:#1976d2,color:#000
    style Difficulty fill:#ba68c8,stroke:#7b1fa2,color:#fff

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (í”„ë¡¬í”„íŠ¸ êµ¬ì„± - ë³´ë¼ ê³„ì—´)
    style EasyPrompt fill:#ce93d8,stroke:#7b1fa2,color:#000
    style HardPrompt fill:#ce93d8,stroke:#7b1fa2,color:#000
    style Context fill:#ba68c8,stroke:#7b1fa2,color:#fff

    %% ë…¸ë“œ ìŠ¤íƒ€ì¼ (ë‹µë³€ ìƒì„± - ë…¹ìƒ‰ ê³„ì—´)
    style LLM fill:#a5d6a7,stroke:#388e3c,color:#000
    style Response fill:#ba68c8,stroke:#7b1fa2,color:#fff
    style EasyAnswer fill:#81c784,stroke:#2e7d32,color:#000
    style HardAnswer fill:#81c784,stroke:#2e7d32,color:#000
    style User fill:#66bb6a,stroke:#2e7d32,color:#fff
```

---

## 7. ë°°í¬ ì•„í‚¤í…ì²˜ (ì„ íƒ ì‚¬í•­)

### 7.1 ë¡œì»¬ ê°œë°œ í™˜ê²½

```
[ì‚¬ìš©ì ë¸Œë¼ìš°ì €] <--> [Streamlit (localhost:8501)]
                              â†“
                     [main.py + Agent]
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                     â†“                     â†“
[Vector DB (ë¡œì»¬)]    [PostgreSQL (ë¡œì»¬)]   [OpenAI API (í´ë¼ìš°ë“œ)]
```

### 7.2 í´ë¼ìš°ë“œ ë°°í¬ (ë°œí‘œìš©)

```
[ì‚¬ìš©ì] --> [Streamlit Cloud]
                   â†“
         [Agent + Tools (Container)]
                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“              â†“              â†“
[ChromaDB]  [PostgreSQL]  [OpenAI API]
(Docker)     (Docker)      (í´ë¼ìš°ë“œ)
```

---

## 8. ì„±ëŠ¥ ë° í™•ì¥ì„± ê³ ë ¤ì‚¬í•­

### 8.1 ìºì‹± ì „ëµ

```python
# LLM ì‘ë‹µ ìºì‹±
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_llm_call(prompt_hash):
    return llm.invoke(prompt)

# Vector DB ê²€ìƒ‰ ê²°ê³¼ ìºì‹±
@lru_cache(maxsize=50)
def cached_similarity_search(query_hash, k):
    return vectorstore.similarity_search(query, k=k)
```

### 8.2 ë¹„ë™ê¸° ì²˜ë¦¬

```python
import asyncio

async def async_agent_invoke(question, difficulty):
    """ë¹„ë™ê¸° Agent ì‹¤í–‰"""
    result = await agent_executor.ainvoke({
        "question": question,
        "difficulty": difficulty
    })
    return result
```

---

## 9. ì°¸ê³  ìë£Œ

- LangGraph ê³µì‹ ë¬¸ì„œ: https://langchain-ai.github.io/langgraph/
- Langchain Agent ê°€ì´ë“œ: https://python.langchain.com/docs/tutorials/agents/
- Streamlit ê³µì‹ ë¬¸ì„œ: https://docs.streamlit.io/
- ChromaDB ë¬¸ì„œ: https://docs.trychroma.com/
- PostgreSQL ë¬¸ì„œ: https://www.postgresql.org/docs/
